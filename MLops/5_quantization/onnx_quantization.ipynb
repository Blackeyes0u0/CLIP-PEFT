{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "onnx_quantization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F32WW6hu9Uzd",
        "outputId": "26f366cc-3554-483c-ce05-28aeca967aaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.12.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.12.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.12.2->onnx) (1.15.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (1.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.7/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->onnxruntime) (1.2.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m transformers.onnx --model=bert-base-uncased model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYHc_ts59bXs",
        "outputId": "755da622-5fa7-4337-82f1-e7a131f148b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-23 03:08:59.690568: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Using framework PyTorch: 1.12.0+cu113\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "Validating ONNX model...\n",
            "\t-[✓] ONNX model output names match reference model ({'last_hidden_state'})\n",
            "\t- Validating ONNX Model output \"last_hidden_state\":\n",
            "\t\t-[✓] (2, 8, 768) matches (2, 8, 768)\n",
            "\t\t-[✓] all values close (atol: 1e-05)\n",
            "All good, model saved at: model/model.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnxruntime.quantization import quantize_dynamic\n",
        "\n",
        "model_fp32 = 'model/model.onnx'\n",
        "model_quant = 'model/model.quantized.onnx'\n",
        "quantize_dynamic(model_fp32, model_quant)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sdfnWh39cjr",
        "outputId": "bfadf323-37ee-4301-acfd-b8e52e8642f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignore MatMul due to non constant B: /[MatMul_149]\n",
            "Ignore MatMul due to non constant B: /[MatMul_154]\n",
            "Ignore MatMul due to non constant B: /[MatMul_243]\n",
            "Ignore MatMul due to non constant B: /[MatMul_248]\n",
            "Ignore MatMul due to non constant B: /[MatMul_337]\n",
            "Ignore MatMul due to non constant B: /[MatMul_342]\n",
            "Ignore MatMul due to non constant B: /[MatMul_431]\n",
            "Ignore MatMul due to non constant B: /[MatMul_436]\n",
            "Ignore MatMul due to non constant B: /[MatMul_525]\n",
            "Ignore MatMul due to non constant B: /[MatMul_530]\n",
            "Ignore MatMul due to non constant B: /[MatMul_619]\n",
            "Ignore MatMul due to non constant B: /[MatMul_624]\n",
            "Ignore MatMul due to non constant B: /[MatMul_713]\n",
            "Ignore MatMul due to non constant B: /[MatMul_718]\n",
            "Ignore MatMul due to non constant B: /[MatMul_807]\n",
            "Ignore MatMul due to non constant B: /[MatMul_812]\n",
            "Ignore MatMul due to non constant B: /[MatMul_901]\n",
            "Ignore MatMul due to non constant B: /[MatMul_906]\n",
            "Ignore MatMul due to non constant B: /[MatMul_995]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1000]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1089]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1094]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1183]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1188]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -alh model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AGLY3YR9xiJ",
        "outputId": "149461ea-0f5c-4fc6-e70e-5e42e06bca3f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 523M\n",
            "drwxr-xr-x 2 root root 4.0K Jul 23 02:51 .\n",
            "drwxr-xr-x 1 root root 4.0K Jul 23 02:50 ..\n",
            "-rw-r--r-- 1 root root 418M Jul 23 03:09 model.onnx\n",
            "-rw-r--r-- 1 root root 105M Jul 23 03:09 model.quantized.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import onnxruntime as ort\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "encoded_input = tokenizer(\" \".join([\"hello\"]*510), return_tensors='np')\n",
        "\n",
        "session = ort.InferenceSession(\"model/model.onnx\", providers=['CPUExecutionProvider'])\n",
        "quantized_session = ort.InferenceSession(\"model/model.quantized.onnx\", providers=['CPUExecutionProvider'])\n",
        "\n",
        "def benchmark(sess):\n",
        "  start = time.time()\n",
        "  for _ in range(10):\n",
        "    output = sess.run(None, input_feed=dict(encoded_input))\n",
        "  end = time.time()\n",
        "  print(end - start)\n",
        "\n",
        "benchmark(session)\n",
        "benchmark(quantized_session)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETHIwhTm92N5",
        "outputId": "42dd1611-81ab-47f7-dadd-357aa9f7e736"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.39389729499817\n",
            "12.877118349075317\n"
          ]
        }
      ]
    }
  ]
}
