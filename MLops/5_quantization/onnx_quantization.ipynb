{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F32WW6hu9Uzd",
        "outputId": "26f366cc-3554-483c-ce05-28aeca967aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/21/02/ae8e595f45b6c8edee07913892b3b41f5f5f273962ad98851dc6a564bbb9/transformers-4.31.0-py3-none-any.whl.metadata\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting onnx\n",
            "  Downloading onnx-1.14.0-cp38-cp38-macosx_10_12_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnxruntime in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (1.15.1)\n",
            "Requirement already satisfied: filelock in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (22.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (2023.8.8)\n",
            "Requirement already satisfied: requests in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp38-cp38-macosx_10_11_x86_64.whl (4.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.2.tar.gz (35 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from onnx) (4.7.1)\n",
            "Requirement already satisfied: coloredlogs in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: sympy in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: fsspec in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from requests->transformers) (1.26.13)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Users/juniverse/opt/anaconda3/envs/vision00/lib/python3.8/site-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: safetensors\n",
            "  Building wheel for safetensors (pyproject.toml) ... \u001b[?25lerror\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for safetensors \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m \u001b[31m[25 lines of output]\u001b[0m\n",
            "  \u001b[31m   \u001b[0m running bdist_wheel\n",
            "  \u001b[31m   \u001b[0m running build\n",
            "  \u001b[31m   \u001b[0m running build_py\n",
            "  \u001b[31m   \u001b[0m creating build\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-38\n",
            "  \u001b[31m   \u001b[0m creating build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m copying py_src/safetensors/paddle.py -> build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m copying py_src/safetensors/__init__.py -> build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m copying py_src/safetensors/numpy.py -> build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m copying py_src/safetensors/tensorflow.py -> build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m copying py_src/safetensors/torch.py -> build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m copying py_src/safetensors/flax.py -> build/lib.macosx-10.9-x86_64-cpython-38/safetensors\n",
            "  \u001b[31m   \u001b[0m running build_ext\n",
            "  \u001b[31m   \u001b[0m running build_rust\n",
            "  \u001b[31m   \u001b[0m error: can't find Rust compiler\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m To update pip, run:\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m     pip install --upgrade pip\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m and then retry package installation.\n",
            "  \u001b[31m   \u001b[0m \n",
            "  \u001b[31m   \u001b[0m If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
            "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "\u001b[?25h\u001b[31m  ERROR: Failed building wheel for safetensors\u001b[0m\u001b[31m\n",
            "\u001b[0mFailed to build safetensors\n",
            "\u001b[31mERROR: Could not build wheels for safetensors, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers onnx onnxruntime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYHc_ts59bXs",
        "outputId": "755da622-5fa7-4337-82f1-e7a131f148b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/juniverse/opt/anaconda3/envs/vision00/bin/python: Error while finding module specification for 'transformers.onnx' (ModuleNotFoundError: No module named 'transformers')\n"
          ]
        }
      ],
      "source": [
        "!python -m transformers.onnx --model=bert-base-uncased model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "기본적으로 weight 를 저장하기위해 fp32 ( floating points 32-bits)활용.\n",
        "\n",
        "fp32 대신에 fp16, int8과 같은 타입을 활용해서 손실이 생기지만 속도향상.\n",
        "학습에서도 fp16만 사용하거나 섞어서 사용하는 방식있음.\n",
        "\n",
        "## ONNX quantization\n",
        "\n",
        "ONNX 에서 제공하는 quantization은 & 8 bit quantization 지원함.\n",
        "\n",
        "https://onnxruntime.ai/docs/performance/model-optimizations/quantization.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sdfnWh39cjr",
        "outputId": "bfadf323-37ee-4301-acfd-b8e52e8642f0"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'model/model.onnx'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model_fp32 \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel/model.onnx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m model_quant \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmodel/model.quantized.onnx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m quantize_dynamic(model_fp32, model_quant)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vision00/lib/python3.8/site-packages/onnxruntime/quantization/quantize.py:488\u001b[0m, in \u001b[0;36mquantize_dynamic\u001b[0;34m(model_input, model_output, op_types_to_quantize, per_channel, reduce_range, weight_type, nodes_to_quantize, nodes_to_exclude, optimize_model, use_external_data_format, extra_options)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m op_types_to_quantize \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(op_types_to_quantize) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    486\u001b[0m     op_types_to_quantize \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(IntegerOpsRegistry\u001b[39m.\u001b[39mkeys())\n\u001b[0;32m--> 488\u001b[0m model \u001b[39m=\u001b[39m load_model(Path(model_input), optimize_model)\n\u001b[1;32m    490\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMatMulConstBOnly\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m extra_options:\n\u001b[1;32m    491\u001b[0m     extra_options[\u001b[39m\"\u001b[39m\u001b[39mMatMulConstBOnly\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vision00/lib/python3.8/site-packages/onnxruntime/quantization/quant_utils.py:558\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_path, need_optimize)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(model_path: Path, need_optimize: \u001b[39mbool\u001b[39m):\n\u001b[1;32m    557\u001b[0m     \u001b[39mwith\u001b[39;00m tempfile\u001b[39m.\u001b[39mTemporaryDirectory(prefix\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mort.quant.\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m quant_tmp_dir:\n\u001b[0;32m--> 558\u001b[0m         \u001b[39mif\u001b[39;00m need_optimize \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m model_has_external_data(model_path):\n\u001b[1;32m    559\u001b[0m             opt_model_path \u001b[39m=\u001b[39m Path(quant_tmp_dir)\u001b[39m.\u001b[39mjoinpath(\u001b[39m\"\u001b[39m\u001b[39mmodel.onnx\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    560\u001b[0m             optimize_model(model_path, opt_model_path)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vision00/lib/python3.8/site-packages/onnxruntime/quantization/quant_utils.py:491\u001b[0m, in \u001b[0;36mmodel_has_external_data\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodel_has_external_data\u001b[39m(model_path: Path):\n\u001b[0;32m--> 491\u001b[0m     model \u001b[39m=\u001b[39m onnx\u001b[39m.\u001b[39;49mload(model_path\u001b[39m.\u001b[39;49mas_posix(), load_external_data\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    492\u001b[0m     \u001b[39mfor\u001b[39;00m intializer \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minitializer:\n\u001b[1;32m    493\u001b[0m         \u001b[39mif\u001b[39;00m external_data_helper\u001b[39m.\u001b[39muses_external_data(intializer):\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vision00/lib/python3.8/site-packages/onnx/__init__.py:183\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(f, format, load_external_data)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_model\u001b[39m(\n\u001b[1;32m    165\u001b[0m     f: IO[\u001b[39mbytes\u001b[39m] \u001b[39m|\u001b[39m \u001b[39mstr\u001b[39m,\n\u001b[1;32m    166\u001b[0m     \u001b[39mformat\u001b[39m: _SupportedFormat \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mprotobuf\u001b[39m\u001b[39m\"\u001b[39m,  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     load_external_data: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    168\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ModelProto:\n\u001b[1;32m    169\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Loads a serialized ModelProto into memory.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[1;32m    171\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39m        Loaded in-memory ModelProto.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     model \u001b[39m=\u001b[39m load_model_from_string(_load_bytes(f), \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mformat\u001b[39m)\n\u001b[1;32m    185\u001b[0m     \u001b[39mif\u001b[39;00m load_external_data:\n\u001b[1;32m    186\u001b[0m         model_filepath \u001b[39m=\u001b[39m _get_file_path(f)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/vision00/lib/python3.8/site-packages/onnx/__init__.py:143\u001b[0m, in \u001b[0;36m_load_bytes\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m    141\u001b[0m     content \u001b[39m=\u001b[39m typing\u001b[39m.\u001b[39mcast(IO[\u001b[39mbytes\u001b[39m], f)\u001b[39m.\u001b[39mread()\n\u001b[1;32m    142\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(typing\u001b[39m.\u001b[39;49mcast(\u001b[39mstr\u001b[39;49m, f), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m readable:\n\u001b[1;32m    144\u001b[0m         content \u001b[39m=\u001b[39m readable\u001b[39m.\u001b[39mread()\n\u001b[1;32m    145\u001b[0m \u001b[39mreturn\u001b[39;00m content\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/model.onnx'"
          ]
        }
      ],
      "source": [
        "import onnx\n",
        "from onnxruntime.quantization import quantize_dynamic\n",
        "\n",
        "model_fp32 = 'model/model.onnx'\n",
        "model_quant = 'model/model.quantized.onnx'\n",
        "quantize_dynamic(model_fp32, model_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AGLY3YR9xiJ",
        "outputId": "149461ea-0f5c-4fc6-e70e-5e42e06bca3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 523M\n",
            "drwxr-xr-x 2 root root 4.0K Jul 23 02:51 .\n",
            "drwxr-xr-x 1 root root 4.0K Jul 23 02:50 ..\n",
            "-rw-r--r-- 1 root root 418M Jul 23 03:09 model.onnx\n",
            "-rw-r--r-- 1 root root 105M Jul 23 03:09 model.quantized.onnx\n"
          ]
        }
      ],
      "source": [
        "!ls -alh model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETHIwhTm92N5",
        "outputId": "42dd1611-81ab-47f7-dadd-357aa9f7e736"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17.39389729499817\n",
            "12.877118349075317\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import onnxruntime as ort\n",
        "from transformers import BertTokenizerFast\n",
        "\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
        "encoded_input = tokenizer(\" \".join([\"hello\"]*510), return_tensors='np')\n",
        "\n",
        "session = ort.InferenceSession(\"model/model.onnx\", providers=['CPUExecutionProvider'])\n",
        "quantized_session = ort.InferenceSession(\"model/model.quantized.onnx\", providers=['CPUExecutionProvider'])\n",
        "\n",
        "def benchmark(sess):\n",
        "  start = time.time()\n",
        "  for _ in range(10):\n",
        "    output = sess.run(None, input_feed=dict(encoded_input))\n",
        "  end = time.time()\n",
        "  print(end - start)\n",
        "\n",
        "benchmark(session)\n",
        "benchmark(quantized_session)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "onnx_quantization.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
