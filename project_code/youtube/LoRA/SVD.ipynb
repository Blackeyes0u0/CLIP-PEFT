{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full rank :  10    low rank :  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([5.2156, 5.1459, 3.9245, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy\n",
    "\n",
    "w = torch.randn(10,11)\n",
    "\n",
    "u,s,v = torch.svd(w)\n",
    "\n",
    "recover = u@torch.diag(s)@v.T\n",
    "\n",
    "full_rank = len(s)\n",
    "low_rank = 3\n",
    "print('full rank : ',full_rank,'   low rank : ',low_rank)\n",
    "x = torch.zeros(full_rank-low_rank)\n",
    "low_s = torch.cat( (s[:low_rank],x),dim=0)\n",
    "low_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD를 해서 복원하면 완전히 같지는 않다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = 0\n",
    "non_counts = 5\n",
    "for i in range(10):\n",
    "    for j in range(11):\n",
    "        if recover[i][j]==w[i][j]:\n",
    "            counts+=1\n",
    "        # else:\n",
    "        #     non_counts-=1\n",
    "        #     print(recover[i][j].numpy(),w[i][j].numpy())\n",
    "    #     if non_counts==0:\n",
    "    #         break\n",
    "    # break\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full rank :  512    low rank :  100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터 세트 로드\n",
    "# train_data = torchvision.datasets.ImageFolder(\n",
    "#     \"data/train\",\n",
    "#     transform=transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# 변환기 정의\n",
    "def normalize(x):\n",
    "    return x / x.std()\n",
    "\n",
    "# 데이터 세트 변환\n",
    "# train_data = train_data.map(normalize, batch_size=1)\n",
    "\n",
    "# 모델 정의\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = torchvision.models.resnet18(False)\n",
    "        self.linear = torch.nn.Linear(512, 3 * 224 * 224)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.linear(x.view(-1, 512))\n",
    "        x = x.view(-1, 3, 224, 224)\n",
    "        return x\n",
    "\n",
    "# 모델 훈련\n",
    "model = Generator()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     for data in train_data:\n",
    "#         img, _ = data\n",
    "#         img = img.float()\n",
    "#         output = model(img)\n",
    "#         loss = criterion(output, img)\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "# 모델 평가\n",
    "# test_data = torchvision.datasets.ImageFolder(\n",
    "#     \"data/test\",\n",
    "#     transform=transforms.Compose([\n",
    "#         transforms.Resize((224, 224)),\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "#     ])\n",
    "# )\n",
    "\n",
    "# correct = 0\n",
    "# total = 0\n",
    "# for data in test_data:\n",
    "#     img, gt = data\n",
    "#     img = img.float()\n",
    "#     output = model(img)\n",
    "#     output = output.argmax(dim=1)\n",
    "#     gt = gt.argmax(dim=1)\n",
    "#     correct += (output == gt).sum().item()\n",
    "#     total += len(gt)\n",
    "\n",
    "# accuracy = correct / total\n",
    "# print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# 저등급 적응\n",
    "def low_rank_adaptation(W, r):\n",
    "    U, s, V = torch.svd(W)\n",
    "    \n",
    "    full_rank = len(s)\n",
    "    low_rank = r\n",
    "    print('full rank : ',full_rank,'   low rank : ',low_rank)\n",
    "    x = torch.zeros(full_rank-low_rank)\n",
    "    low_s = torch.cat( (s[:low_rank],x),dim=0)\n",
    "    return U @ torch.diag(low_s) @ V.T\n",
    "\n",
    "# 모델 매개변수 저등급화\n",
    "W = model.linear.weight.data\n",
    "W_low_rank = low_rank_adaptation(W, 100)\n",
    "model.linear.weight.data = W_low_rank\n",
    "\n",
    "# 모델 평가\n",
    "correct = 0\n",
    "total = 0\n",
    "# for data in test_data:\n",
    "#     img, gt = data\n",
    "#     img = img.float()\n",
    "#     output = model(img)\n",
    "#     output = output.argmax(dim=1)\n",
    "#     gt = gt.argmax(dim=1)\n",
    "#     correct += (output == gt).sum().item()\n",
    "#     total += len(gt)\n",
    "\n",
    "# accuracy = correct / total\n",
    "# print(\"Accuracy after low-rank adaptation:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# W_low_rank = low_rank_adaptation(W, 100)\n",
    "# model.linear.weight.data = W_low_rank\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "veda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
