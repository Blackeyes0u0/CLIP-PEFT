{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 뉴럴넷으로 패션 아이템 구분하기\n",
    "Fashion MNIST 데이터셋과 앞서 배운 인공신경망을 이용하여 패션아이템을 구분해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = True,\n",
    "    download  = True,\n",
    "    transform = transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './.data/', \n",
    "    train     = False,\n",
    "    download  = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 뉴럴넷으로 Fashion MNIST 학습하기\n",
    "\n",
    "입력 `x` 는 `[배치크기, 색, 높이, 넓이]`로 이루어져 있습니다.\n",
    "`x.size()`를 해보면 `[64, 1, 28, 28]`이라고 표시되는 것을 보실 수 있습니다.\n",
    "Fashion MNIST에서 이미지의 크기는 28 x 28, 색은 흑백으로 1 가지 입니다.\n",
    "그러므로 입력 x의 총 특성값 갯수는 28 x 28 x 1, 즉 784개 입니다.\n",
    "\n",
    "우리가 사용할 모델은 3개의 레이어를 가진 인공신경망 입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n",
      "tensor([9, 1, 0, 7, 0, 1, 6, 6, 2, 4, 4, 0, 4, 3, 3, 2, 1, 8, 3, 8, 8, 2, 7, 9,\n",
      "        5, 3, 3, 6, 7, 2, 4, 1, 9, 5, 3, 5, 7, 5, 4, 4, 7, 2, 4, 0, 6, 3, 9, 6,\n",
      "        7, 4, 4, 0, 9, 5, 8, 5, 3, 9, 9, 9, 8, 9, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for x in train_loader:\n",
    "    # print(x)\n",
    "    print(len(x))\n",
    "    print(x[0].shape)\n",
    "    print(x[1].shape)\n",
    "    print(x[1])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.text1 = nn.Linear(784,256)\n",
    "        self.text1 = nn.Linear(256,128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# class textnet(nn.Module):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super(textnet,self).__init__(*args, **kwargs)\n",
    "#         self.fc1 = nn.Linear(784,77)\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         x = x.view(-1,784)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         return x\n",
    "\n",
    "# class labelnet(nn.Module):\n",
    "#     def __init__(self, *args, **kwargs) -> None:\n",
    "#         super(textnet,self).__init__(*args, **kwargs)\n",
    "#         self.fc1 = nn.Linear(784,77)\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         x = x.view(-1,784)\n",
    "#         x = F.relu(self.fc1(x))\n",
    "#         return x\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        self.text1 = nn.Linear(784,256)\n",
    "        self.text1 = nn.Linear(256,128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 준비하기\n",
    "\n",
    "`to()` 함수는 모델의 파라미터들을 지정한 곳으로 보내는 역할을 합니다.\n",
    "일반적으로 CPU 1개만 사용할 경우 필요는 없지만,\n",
    "GPU를 사용하고자 하는 경우 `to(\"cuda\")`로 지정하여 GPU로 보내야 합니다.\n",
    "지정하지 않을 경우 계속 CPU에 남아 있게 되며 빠른 훈련의 이점을 누리실 수 없습니다.\n",
    "\n",
    "최적화 알고리즘으로 파이토치에 내장되어 있는 `optim.SGD`를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model        = Net().to(DEVICE)\n",
    "optimizer    = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt = torch.optim.SGD(\n",
    "#     params=[Net.parameters(), Net2.parameters()], lr=0.001, momentum=0.9\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64, 10])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    # 학습 데이터를 DEVICE의 메모리로 보냄\n",
    "    data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "    \n",
    "    print(data.shape)\n",
    "    output = model(data)\n",
    "    \n",
    "    print(output.shape)\n",
    "    print(target.shape) \n",
    "    criterion = kl_divergence\n",
    "    # loss = kl_divergence(output, target)\n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.exp(torch.randn(2,10))\n",
    "b = torch.sum(torch.exp(a), dim=0)\n",
    "\n",
    "a_softmax = torch.softmax(a, dim=0)\n",
    "print(a_softmax.shape) # torch.Size([64, 10])\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/juniverse/Downloads/neural_network.ipynb 셀 16\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X36sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m torch\u001b[39m.\u001b[39mexp(output)\u001b[39m.\u001b[39mshape \u001b[39m# torch.Size([64,10])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X36sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m torch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mexp(output),dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mshape \u001b[39m# torch.Size([64])\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X36sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m a_div_b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdiv(a, b)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X36sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# torch.exp(output)/torch.sum(torch.exp(output),dim=1)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "torch.exp(output).shape # torch.Size([64,10])\n",
    "torch.sum(torch.exp(output),dim=1).shape # torch.Size([64])\n",
    "a_div_b = torch.div(a, b)\n",
    "# torch.exp(output)/torch.sum(torch.exp(output),dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa =torch.sum(output,dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/juniverse/Downloads/neural_network.ipynb 셀 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m (\u001b[39m-\u001b[39m\u001b[39m1.0\u001b[39m)\u001b[39m*\u001b[39mtorch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39;49mexp(output)\u001b[39m/\u001b[39;49mtorch\u001b[39m.\u001b[39;49msum(torch\u001b[39m.\u001b[39;49mexp(output),dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\u001b[39m*\u001b[39mtarget)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (10) must match the size of tensor b (64) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "\n",
    "(-1.0)*torch.sum(torch.log(torch.exp(output)/torch.sum(torch.exp(output),dim=1))*target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def kl_divergence(output,target):\n",
    "    H_pq = (-1.0)*torch.sum(torch.log(torch.exp(output)/torch.sum(torch.exp(output)))*target)\n",
    "    H_p = -torch.sum(torch.log(torch.exp(target)/torch.sum(torch.exp(target))))    \n",
    "    return H_pq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer):\n",
    "    model.train() # train mode , calculate gradient!!!\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 학습 데이터를 DEVICE의 메모리로 보냄\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criterion = kl_divergence\n",
    "        loss = kl_divergence(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            # 모든 오차 더하기\n",
    "            # test_loss += F.cross_entropy(output, target,\n",
    "            #                              reduction='sum').item()\n",
    "            test_loss += kl_divergence(output, target,\n",
    "                                         reduction='sum').item()\n",
    "            \n",
    "            # 가장 큰 값을 가진 클래스가 모델의 예측입니다.\n",
    "            # 예측과 정답을 비교하여 일치할 경우 correct에 1을 더합니다.\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 코드 돌려보기\n",
    "\n",
    "자, 이제 모든 준비가 끝났습니다. 코드를 돌려서 실제로 훈련이 되는지 확인해봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (64) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/juniverse/Downloads/neural_network.ipynb 셀 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, EPOCHS \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     train(model, train_loader, optimizer)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m evaluate(model, test_loader)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m] Test Loss: \u001b[39m\u001b[39m{:.4f}\u001b[39;00m\u001b[39m, Accuracy: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m           epoch, test_loss, test_accuracy))\n",
      "\u001b[1;32m/Users/juniverse/Downloads/neural_network.ipynb 셀 22\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m criterion \u001b[39m=\u001b[39m kl_divergence\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m loss \u001b[39m=\u001b[39m kl_divergence(output, target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "\u001b[1;32m/Users/juniverse/Downloads/neural_network.ipynb 셀 22\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkl_divergence\u001b[39m(output,target):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     H_pq \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39msum(target\u001b[39m*\u001b[39;49mtorch\u001b[39m.\u001b[39;49mlog(torch\u001b[39m.\u001b[39;49mexp(output)\u001b[39m/\u001b[39;49mtorch\u001b[39m.\u001b[39;49msum(torch\u001b[39m.\u001b[39;49mexp(output))))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     H_p \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mtorch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mlog(torch\u001b[39m.\u001b[39mexp(target)\u001b[39m/\u001b[39mtorch\u001b[39m.\u001b[39msum(torch\u001b[39m.\u001b[39mexp(target))))    \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/juniverse/Downloads/neural_network.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m H_pq\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (64) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
