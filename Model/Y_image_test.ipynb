{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1584],\n",
       "        [-0.1584]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((x,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200]) functionc(\n",
      "  (layer1): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class functionc(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(functionc,self).__init__()\n",
    "        self.layer1 = nn.Linear(1,1) # ax + bx +c\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # x_c = self.layer1(x)\n",
    "        # y =  x_c\n",
    "        # x = torch.cat((x**2,x))\n",
    "        # x = torch.cat((x,x))\n",
    "        y = self.layer1(x)\n",
    "        return y\n",
    "\n",
    "x = torch.randn(1)\n",
    "model = functionc()\n",
    "\n",
    "print(y.shape,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1]) tensor([0.6823])\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "x = torch.randn(100)\n",
    "\n",
    "y_noise = torch.rand_like(x)/10000\n",
    "y = x**2 + y_noise#+x -1\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "losses = []\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for t,l in zip(x,y):\n",
    "        t = t.view(1)\n",
    "        print(t.shape,t)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920.1608974221854\n",
      "980.2761790134246\n",
      "1045.310549227026\n",
      "948.3748958832584\n",
      "1039.349765284278\n",
      "1002.3099746222142\n",
      "915.3746150353909\n",
      "935.433474558231\n",
      "852.0179939940572\n",
      "1097.1686988009023\n",
      "1043.2719027301791\n",
      "913.345213494089\n",
      "974.9892131341621\n",
      "947.640390174929\n",
      "1015.1925799928431\n",
      "1013.9833407964943\n",
      "980.7965435747756\n",
      "948.4851291103987\n",
      "1032.8969557851087\n",
      "856.6052803936655\n",
      "946.274758366779\n",
      "1039.6189722664271\n",
      "1022.386949970678\n",
      "1045.3034228477627\n",
      "911.8505708009616\n",
      "1004.9154563595148\n",
      "842.0430841203779\n",
      "811.4580070205411\n",
      "1092.2538089914015\n",
      "1122.4621111992747\n",
      "937.7072121411329\n",
      "1005.0165671943687\n",
      "923.8061344405869\n",
      "1051.5202538906597\n",
      "960.3818247611634\n",
      "1068.6863475466962\n",
      "972.2051185765376\n",
      "1072.3302074262756\n",
      "969.162431496894\n",
      "906.7463070202866\n",
      "857.4494433498476\n",
      "908.9588814821134\n",
      "1012.9018832739821\n",
      "1099.6797491281322\n",
      "998.8154086148425\n",
      "1034.2913516986591\n",
      "1096.5558506937232\n",
      "898.2441438496535\n",
      "1122.5605855985182\n",
      "1135.2816524750087\n",
      "1008.1899939845316\n",
      "1039.334515693714\n",
      "1006.3104268109892\n",
      "890.1612941946369\n",
      "1015.6506202528835\n",
      "954.9843308482086\n",
      "993.9853642657399\n",
      "1076.4277827828191\n",
      "1090.6020035285037\n",
      "1134.4770505178103\n",
      "1011.5419647614399\n",
      "1036.8964656221215\n",
      "1116.5213871379383\n",
      "1023.5045612222166\n",
      "964.353080068453\n",
      "976.8392228464763\n",
      "956.1150024655835\n",
      "922.4877803868148\n",
      "1078.9483273016522\n",
      "1109.8537543015555\n",
      "1019.6522384069394\n",
      "1061.328809685343\n",
      "1021.8490200540109\n",
      "940.2034200006165\n",
      "1016.8776728166267\n",
      "956.2650633890007\n",
      "1060.8125607166876\n",
      "948.7992426363562\n",
      "1012.6401861670893\n",
      "1099.09516194975\n",
      "965.7086401432753\n",
      "837.641236550352\n",
      "1015.2614006257863\n",
      "1138.0689673151755\n",
      "1049.7126214783639\n",
      "900.2489684331813\n",
      "954.4629658343038\n",
      "857.5107471534284\n",
      "1031.0797392698005\n",
      "1030.2938979298744\n",
      "900.1009171098704\n",
      "1014.1081817965023\n",
      "1023.0099184719147\n",
      "983.9971403265372\n",
      "972.843171984634\n",
      "1063.8938642431895\n",
      "1067.5060953056673\n",
      "1055.344722676357\n",
      "1063.863974783104\n",
      "994.5145882388191\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "\n",
    "x = torch.randn(100)\n",
    "\n",
    "y_noise = torch.rand_like(x)/10000\n",
    "y = x**2 + y_noise#+x -1\n",
    "bias = torch.ones(100)*3\n",
    "y = torch.cat((3*x,bias))\n",
    "\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "# loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "losses = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for t,l in zip(x,y):\n",
    "        t = t.view(1)\n",
    "        model.zero_grad()\n",
    "        model = functionc()\n",
    "        predict = model(t)\n",
    "\n",
    "        loss = loss_function(l,predict)\n",
    "\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n",
    "    print(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functionc(\n",
       "  (layer1): Linear(in_features=1, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a*x**2 + b*x**1 + c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([[0.4440]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.5884], requires_grad=True))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layer1.weight , model.layer1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.4094], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x = torch.tensor([2.])\n",
    "model = functionc()\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.layer1 = nn.Linear(\n",
    "            \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1999 W: 0.509, b: -0.114 Cost: 48.731510\n",
      "Epoch  100/1999 W: 2.712, b: 1.381 Cost: 0.377661\n",
      "Epoch  200/1999 W: 2.560, b: 1.728 Cost: 0.233371\n",
      "Epoch  300/1999 W: 2.440, b: 2.000 Cost: 0.144209\n",
      "Epoch  400/1999 W: 2.346, b: 2.214 Cost: 0.089113\n",
      "Epoch  500/1999 W: 2.272, b: 2.382 Cost: 0.055066\n",
      "Epoch  600/1999 W: 2.214, b: 2.514 Cost: 0.034028\n",
      "Epoch  700/1999 W: 2.168, b: 2.618 Cost: 0.021027\n",
      "Epoch  800/1999 W: 2.132, b: 2.700 Cost: 0.012993\n",
      "Epoch  900/1999 W: 2.104, b: 2.764 Cost: 0.008029\n",
      "Epoch 1000/1999 W: 2.082, b: 2.814 Cost: 0.004961\n",
      "Epoch 1100/1999 W: 2.064, b: 2.854 Cost: 0.003066\n",
      "Epoch 1200/1999 W: 2.050, b: 2.885 Cost: 0.001895\n",
      "Epoch 1300/1999 W: 2.040, b: 2.910 Cost: 0.001171\n",
      "Epoch 1400/1999 W: 2.031, b: 2.929 Cost: 0.000723\n",
      "Epoch 1500/1999 W: 2.024, b: 2.944 Cost: 0.000447\n",
      "Epoch 1600/1999 W: 2.019, b: 2.956 Cost: 0.000276\n",
      "Epoch 1700/1999 W: 2.015, b: 2.966 Cost: 0.000171\n",
      "Epoch 1800/1999 W: 2.012, b: 2.973 Cost: 0.000105\n",
      "Epoch 1900/1999 W: 2.009, b: 2.979 Cost: 0.000065\n"
     ]
    }
   ],
   "source": [
    "# 데이터\n",
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])\n",
    "y_train = torch.FloatTensor([[5], [7], [9]])\n",
    "# y_train = torch.FloatTensor([[5], [17], [37]])\n",
    "# 모델 초기화\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "b = torch.zeros(1, requires_grad=True)\n",
    "# optimizer 설정\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = Model()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "nb_epochs = 1999 # 원하는만큼 경사 하강법을 반복\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs,model.linear.weight.item(),model.linear.bias.item(), cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([51.5665], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([4.])\n",
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "veda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
