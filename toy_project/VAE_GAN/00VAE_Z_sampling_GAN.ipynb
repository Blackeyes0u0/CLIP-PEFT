{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNyqIFNQRfLi"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python\n",
        "# coding: utf-8\n",
        "\n",
        "# # 뉴럴넷으로 패션 아이템 구분하기\n",
        "# Fashion MNIST 데이터셋과 앞서 배운 인공신경망을 이용하여 패션아이템을 구분해봅니다.\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms, datasets, utils\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib import cm\n",
        "import numpy as np\n",
        "import torch.nn.init as init # 초기화 관련 모듈\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print('Using Device : ',DEVICE)\n",
        "\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "\n",
        "# ## 데이터셋 불러오기\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "\n",
        "trainset = datasets.FashionMNIST(\n",
        "    root      = './data/',\n",
        "    train     = True,\n",
        "    download  = True,\n",
        "    transform = transform\n",
        ")\n",
        "testset = datasets.FashionMNIST(\n",
        "    root      = './data/',\n",
        "    train     = False,\n",
        "    download  = True,\n",
        "    transform = transform\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = trainset,\n",
        "    batch_size  = BATCH_SIZE,\n",
        "    shuffle     = False,\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = testset,\n",
        "    batch_size  = BATCH_SIZE,\n",
        "    shuffle     = False,\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter       = iter(train_loader) #배치 1개만 뽑아 데이터가 생긴 형태를 살펴보겠습니다\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# 여러 이미지 모아보기\n",
        "img   = utils.make_grid(images, padding=0) # util.make_grid() 함수를 이용해 여러 이미지를 하나로 모아 하나의 이미지로 만듭니다\n",
        "npimg = img.numpy() # img는 파이토치 텐서입니다. numpy()함수로 맷플롯립과 호환이 되는 넘파이 행렬로 바꿔줍니다.\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(np.transpose(npimg, (1,2,0))) #np.transpose() 함수를 이용해 첫 번째(0번째) 차원을 맨 뒤로 보냅니다\n",
        "plt.show()\n",
        "# 여러 개의 패션 아이템이 흑백으로 나열되는 것을 볼 수 있습니다"
      ],
      "metadata": {
        "id": "Hc5NrbtwSmDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# classificaiton fashion MNIST"
      ],
      "metadata": {
        "id": "d4sgBWF5poac"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 784)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "model        = Net().to(DEVICE)\n",
        "optimizer    = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "def train(model, train_loader, optimizer):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # 학습 데이터를 DEVICE의 메모리로 보냄\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            # 모든 오차 더하기\n",
        "            test_loss += F.cross_entropy(output, target,\n",
        "                                         reduction='sum').item()\n",
        "\n",
        "            # 가장 큰 값을 가진 클래스가 모델의 예측입니다.\n",
        "            # 예측과 정답을 비교하여 일치할 경우 correct에 1을 더합니다.\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "\n",
        "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ],
      "metadata": {
        "id": "1iPQoe8bR5ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Autoencoders"
      ],
      "metadata": {
        "id": "l2trODR0p3lF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Model1\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Linear(28*28, 144),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(144, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 3),   # 입력의 특징을 3차원으로 압축합니다\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        return encoded\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Decoder,self).__init__()\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(3, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 144),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(144, 28*28),\n",
        "            nn.Sigmoid(),       # 픽셀당 0과 1 사이로 값을 출력합니다\n",
        "        )\n",
        "\n",
        "    def forward(self,z):\n",
        "        decoded = self.decoder(z)\n",
        "        return decoded\n",
        "\n",
        "class Descriminator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Descriminator,self).__init__()\n",
        "        self.des = nn.Sequential(\n",
        "            nn.Linear(28*28,124),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(124,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12,2)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.des(x)\n",
        "        return x\n",
        "\n",
        "# Model2\n",
        "\n",
        "num_epoch = 200\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "img_size = 28 * 28\n",
        "num_channel = 1\n",
        "dir_name = \"GAN_results\"\n",
        "\n",
        "noise_size = 3\n",
        "hidden_size1 = 256\n",
        "hidden_size2 = 512\n",
        "hidden_size3 = 1024\n",
        "\n",
        "\n",
        "# Declares discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(img_size, hidden_size3)\n",
        "        self.linear2 = nn.Linear(hidden_size3, hidden_size2)\n",
        "        self.linear3 = nn.Linear(hidden_size2, hidden_size1)\n",
        "        self.linear4 = nn.Linear(hidden_size1, 1)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.linear1(x))\n",
        "        x = self.leaky_relu(self.linear2(x))\n",
        "        x = self.leaky_relu(self.linear3(x))\n",
        "        x = self.linear4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Declares generator & encoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(noise_size, hidden_size1)\n",
        "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.linear3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.linear4 = nn.Linear(hidden_size3, img_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.relu(self.linear3(x))\n",
        "        x = self.linear4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(img_size,hidden_size3)\n",
        "        self.linear2 = nn.Linear(hidden_size3,hidden_size2)\n",
        "        self.linear3 = nn.Linear(hidden_size2,hidden_size1)\n",
        "        self.linear4 = nn.Linear(hidden_size1,noise_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh(x)\n",
        "        self.bn = nn.BatchNorm1d(3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.relu(self.linear3(x))\n",
        "        x = self.linear4(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "encoder = Encoder().to(DEVICE) # 정의한 모델을 GPU로 납치\n",
        "decoder = Decoder().to(DEVICE)\n",
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        init.kaiming_uniform_(m.weight.data)\n",
        "\n",
        "encoder.apply(weight_init)\n",
        "decoder.apply(weight_init)\n",
        "\n",
        "# descriminator = Descriminator().to(DEVICE)\n",
        "# descriminator.apply(weight_init)\n",
        "\n",
        "optimizer1 = torch.optim.Adam(encoder.parameters(), lr=0.005)\n",
        "optimizer2 = torch.optim.Adam(decoder.parameters(), lr =0.005)\n",
        "# optimizer2 = torch.optim.Adam(descriminator.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "# criterion = nn.CrossEntropyLoss() # 이렇게 하면 흑백으로 됨.. 참과 거짓..?\n",
        "\n",
        "# 원본 이미지를 시각화 하기 (첫번째 열)\n",
        "view_data = trainset.data[:5].view(-1, 28*28)\n",
        "view_data = view_data.type(torch.FloatTensor)/255.\n",
        "\n",
        "def train(encoder,decoder, train_loader):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_loss = 0\n",
        "    for step, (x, label) in enumerate(train_loader):\n",
        "        x = x.view(-1, 28*28).to(DEVICE)\n",
        "        y = x.view(-1, 28*28).to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "\n",
        "        encoded= encoder(x)\n",
        "        decoded= decoder(encoded)\n",
        "        loss = criterion(decoded, y)\n",
        "        total_loss+=loss\n",
        "        optimizer1.zero_grad()\n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "        optimizer2.step()\n",
        "    print('loss :',total_loss)\n",
        "\n",
        "\n",
        "\n",
        "EPOCH = 7\n",
        "\n",
        "for epoch in range(1, EPOCH+1):\n",
        "    print(\"[Epoch {}]\".format(epoch))\n",
        "\n",
        "    train(encoder,decoder, train_loader)\n",
        "\n",
        "    # 디코더에서 나온 이미지를 시각화 하기 (두번째 열)\n",
        "    test_x = view_data.to(DEVICE)\n",
        "    zz = encoder(test_x)\n",
        "    decoded_data = decoder(zz)\n",
        "\n",
        "    # 원본과 디코딩 결과 비교해보기\n",
        "    f, a = plt.subplots(2, 5, figsize=(5, 2))\n",
        "    for i in range(5):\n",
        "        img = np.reshape(view_data.data.numpy()[i],(28, 28))\n",
        "        a[0][i].imshow(img, cmap='gray')\n",
        "        a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
        "\n",
        "    for i in range(5):\n",
        "        img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28))\n",
        "        a[1][i].imshow(img, cmap='gray')\n",
        "        a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PHy5F2oxLDun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Descriminator(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Descriminator,self).__init__()\n",
        "        self.des = nn.Sequential(\n",
        "            nn.Linear(28*28,124),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(124,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,12),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(12,2)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x = self.des(x)\n",
        "        return x\n",
        "\n",
        "num_epoch = 200\n",
        "batch_size = 100\n",
        "learning_rate = 0.0002\n",
        "img_size = 28 * 28\n",
        "num_channel = 1\n",
        "dir_name = \"GAN_results\"\n",
        "\n",
        "noise_size = 3\n",
        "hidden_size0 = 64\n",
        "hidden_size1 = 256\n",
        "hidden_size2 = 512\n",
        "hidden_size3 = 1024\n",
        "\n",
        "\n",
        "# Declares discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.linear1 = nn.Linear(img_size, hidden_size3)\n",
        "        self.linear2 = nn.Linear(hidden_size3, hidden_size2)\n",
        "        self.linear3 = nn.Linear(hidden_size2, hidden_size1)\n",
        "        self.linear4 = nn.Linear(hidden_size1, 1)\n",
        "        self.leaky_relu = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.linear1(x))\n",
        "        x = self.leaky_relu(self.linear2(x))\n",
        "        x = self.leaky_relu(self.linear3(x))\n",
        "        x = self.linear4(x)\n",
        "        x = self.sigmoid(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Declares generator & encoder\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.linear0 = nn.Linear(noise_size, hidden_size0)\n",
        "        self.linear1 = nn.Linear(hidden_size0, hidden_size1)\n",
        "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.linear3 = nn.Linear(hidden_size2, hidden_size3)\n",
        "        self.linear4 = nn.Linear(hidden_size3, img_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.linear0(x))\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.relu(self.linear3(x))\n",
        "        x = self.linear4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(img_size,hidden_size3)\n",
        "        self.linear2 = nn.Linear(hidden_size3,hidden_size2)\n",
        "        self.linear3 = nn.Linear(hidden_size2,hidden_size1)\n",
        "        self.linear4 = nn.Linear(hidden_size1,hidden_size0)\n",
        "        self.linear5 = nn.Linear(hidden_size0,noise_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.bn = nn.BatchNorm1d(3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.linear1(x))\n",
        "        x = self.relu(self.linear2(x))\n",
        "        x = self.relu(self.linear3(x))\n",
        "        x = self.relu(self.linear4(x))\n",
        "        x = self.linear5(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.tanh(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "discriminator = Discriminator().to(DEVICE)\n",
        "encoder = Encoder().to(DEVICE) # 정의한 모델을 GPU로 납치\n",
        "decoder = Decoder().to(DEVICE)\n",
        "\n",
        "def weight_init(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        init.kaiming_uniform_(m.weight.data)\n",
        "\n",
        "encoder.apply(weight_init)\n",
        "decoder.apply(weight_init)\n",
        "discriminator.apply(weight_init)\n",
        "\n",
        "# descriminator = Descriminator().to(DEVICE)\n",
        "# descriminator.apply(weight_init)\n",
        "\n",
        "optimizer1 = torch.optim.Adam(encoder.parameters(), lr=0.005)\n",
        "optimizer2 = torch.optim.Adam(decoder.parameters(), lr =0.005)\n",
        "# optimizer2 = torch.optim.Adam(descriminator.parameters(), lr=0.001)\n",
        "criterion = nn.MSELoss()\n",
        "# criterion = nn.CrossEntropyLoss() # 이렇게 하면 흑백으로 됨.. 참과 거짓..?\n",
        "\n",
        "# 원본 이미지를 시각화 하기 (첫번째 열)\n",
        "view_data = trainset.data[:5].view(-1, 28*28)\n",
        "view_data = view_data.type(torch.FloatTensor)/255.\n",
        "\n",
        "def train(encoder,decoder, train_loader):\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    total_loss = 0\n",
        "    for step, (x, label) in enumerate(train_loader):\n",
        "        x = x.view(-1, 28*28).to(DEVICE)\n",
        "        y = x.view(-1, 28*28).to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "\n",
        "        encoded= encoder(x)\n",
        "        decoded= decoder(encoded)\n",
        "        loss = criterion(decoded, y)\n",
        "        total_loss+=loss\n",
        "        optimizer1.zero_grad()\n",
        "        optimizer2.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer1.step()\n",
        "        optimizer2.step()\n",
        "    print('loss :',total_loss)\n",
        "\n",
        "\n",
        "\n",
        "EPOCH = 3\n",
        "\n",
        "for epoch in range(1, EPOCH+1):\n",
        "    print(\"[Epoch {}]\".format(epoch))\n",
        "\n",
        "    train(encoder,decoder, train_loader)\n",
        "\n",
        "    # 디코더에서 나온 이미지를 시각화 하기 (두번째 열)\n",
        "    test_x = view_data.to(DEVICE)\n",
        "    zz = encoder(test_x)\n",
        "    decoded_data = decoder(zz)\n",
        "\n",
        "    # 원본과 디코딩 결과 비교해보기\n",
        "    f, a = plt.subplots(2, 5, figsize=(5, 2))\n",
        "    for i in range(5):\n",
        "        img = np.reshape(view_data.data.numpy()[i],(28, 28))\n",
        "        a[0][i].imshow(img, cmap='gray')\n",
        "        a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
        "\n",
        "    for i in range(5):\n",
        "        img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28))\n",
        "        a[1][i].imshow(img, cmap='gray')\n",
        "        a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LdsAvUjsNpGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 잠재 변수 보기\n"
      ],
      "metadata": {
        "id": "Kn1_FR-mQrtJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 잠재변수를 3D 플롯으로 시각화\n",
        "view_data = trainset.data[:200].view(-1, 28*28)\n",
        "view_data = view_data.type(torch.FloatTensor)/255.\n",
        "test_x = view_data.to(DEVICE)\n",
        "encoded_data = encoder(test_x)\n",
        "encoded_data = encoded_data.to(\"cpu\")\n",
        "\n",
        "CLASSES = {\n",
        "    0: 'T-shirt/top',\n",
        "    1: 'Trouser',\n",
        "    2: 'Pullover',\n",
        "    3: 'Dress',\n",
        "    4: 'Coat',\n",
        "    5: 'Sandal',\n",
        "    6: 'Shirt',\n",
        "    7: 'Sneaker',\n",
        "    8: 'Bag',\n",
        "    9: 'Ankle boot'\n",
        "}\n",
        "\n",
        "# 데이터 생성\n",
        "\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "ax = Axes3D(fig)\n",
        "\n",
        "X = encoded_data.data[:, 0].numpy()\n",
        "Y = encoded_data.data[:, 1].numpy()\n",
        "Z = encoded_data.data[:, 2].numpy()\n",
        "\n",
        "labels = trainset.targets[:200].numpy()\n",
        "# 클래스 이름과 색상 매핑\n",
        "cm = plt.cm.rainbow\n",
        "\n",
        "# 3D 플롯 생성\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "# 각 데이터 포인트에 클래스 이름과 색상을 지정\n",
        "for x, y, z, s in zip(X, Y, Z, labels):\n",
        "    name = CLASSES[s]\n",
        "    color = cm(int(255*s/9))\n",
        "    ax.text(x, y, z, name, backgroundcolor=color)\n",
        "\n",
        "# 축 범위 설정\n",
        "ax.set_xlim(X.min(), X.max())\n",
        "ax.set_ylim(Y.min(), Y.max())\n",
        "ax.set_zlim(Z.min(), Z.max())\n",
        "\n",
        "# 플롯 표시\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c0j4sieSQtqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VAE로 만들어진 Z를 sampling해서 다시 데이터 셋으로 만들기.\n",
        "\n",
        "sampling_z = torch.randn(0)\n",
        "for x,y in train_loader:\n",
        "    # print(x.shape)\n",
        "    # print(y.shape)\n",
        "    x = x.view(-1,784).to(DEVICE)\n",
        "    z = encoder(x)\n",
        "    z = z.detach().cpu().type(torch.float32)\n",
        "    sampling_z = torch.concat((sampling_z,z),dim=0)\n",
        "print(sampling_z.shape)\n",
        "\n",
        "# noise\n",
        "noise = torch.randn_like(sampling_z)*0.2\n",
        "noise_sampling_z = noise +sampling_z\n",
        "\n",
        "z_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = sampling_z, # not noisy\n",
        "    batch_size  = BATCH_SIZE,\n",
        "    shuffle     = False,\n",
        ")\n",
        "\n",
        "noisy_z_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = noise_sampling_z, #noisy\n",
        "    batch_size  = BATCH_SIZE,\n",
        "    shuffle     = False,\n",
        ")\n"
      ],
      "metadata": {
        "id": "K_CTGT99LJVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GAN\n",
        "\n",
        "위 샘플링된 z를 통해서 GAN을 할것이다. 원래 기본코드와 다르게 간닷."
      ],
      "metadata": {
        "id": "1S5gPu-RPK5p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for step,((x,label),z,noisy_z) in enumerate(zip(train_loader,z_loader,noisy_z_loader)):\n",
        "  print(x.shape)\n",
        "  print(label)\n",
        "  print(z.shape)\n",
        "  print(label.get_device())\n",
        "  print(z.get_device()) # 0이면 gpu -1이면 cpu\n",
        "  print(noisy_z.get_device()) # 0이면 gpu -1이면 cpu\n",
        "  break"
      ],
      "metadata": {
        "id": "56SdLmNP2HQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 잘 만들어지나 실험.\n",
        "\n",
        "for step,((x,label),z,noisy_z) in enumerate(zip(train_loader,z_loader,noisy_z_loader)):\n",
        "  print(x.shape)\n",
        "  print(label)\n",
        "  print(z.shape)\n",
        "  fig = plt.figure(figsize = (10,10))\n",
        "  number_item = 19\n",
        "  plt.subplot(1,3,1)\n",
        "  plt.title('real')\n",
        "  plt.imshow(x[number_item].view(28,28))\n",
        "\n",
        "  # z to decode\n",
        "  z.to('cpu')\n",
        "  decoder.to('cpu')\n",
        "  yyy = decoder(z[number_item])\n",
        "  print(yyy.shape)\n",
        "\n",
        "  plt.subplot(1,3,2)\n",
        "  plt.title('decoded')\n",
        "  plt.imshow(yyy.view(28,28).detach().cpu())\n",
        "\n",
        "\n",
        "  # noisy z to decode\n",
        "  noisy_z.to('cpu')\n",
        "  yyy2 = decoder(noisy_z[number_item])\n",
        "  print(yyy2.shape)\n",
        "\n",
        "  plt.subplot(1,3,3)\n",
        "  plt.title('decoded noisy z')\n",
        "  plt.imshow(yyy2.view(28,28).detach().cpu())\n",
        "  break"
      ],
      "metadata": {
        "id": "qeLKOlQtVwYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator().to(DEVICE)\n",
        "decoder = decoder.to(DEVICE)\n",
        "\n",
        "discriminator.apply(weight_init)\n",
        "\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002)\n",
        "g_optimizer = torch.optim.Adam(decoder.parameters(), lr =0.0002) # generator\n",
        "\n",
        "# 원본 이미지를 시각화 하기 (첫번째 열)\n",
        "view_data = trainset.data[:5].view(-1, 28*28)\n",
        "view_data = view_data.type(torch.FloatTensor)/255.\n",
        "\n",
        "\n",
        "EPOCH = 200\n",
        "device = DEVICE\n",
        "batch_size = 100\n",
        "for epoch in range(1, EPOCH+1):\n",
        "    for step,((x,label),z,noisy_z) in enumerate(zip(train_loader,z_loader,noisy_z_loader)):\n",
        "        real_label = torch.full((batch_size, 1), 1, dtype=torch.float32).to(device)\n",
        "        fake_label = torch.full((batch_size, 1), 0, dtype=torch.float32).to(device)\n",
        "\n",
        "        real_images = images.reshape(batch_size, -1).to(device)\n",
        "\n",
        "        # +---------------------+\n",
        "        # |   train Generator   |\n",
        "        # +---------------------+\n",
        "\n",
        "        # Initialize grad\n",
        "        g_optimizer.zero_grad()\n",
        "        d_optimizer.zero_grad()\n",
        "\n",
        "        z = z.detach().to(device)\n",
        "        # z = torch.randn(batch_size, noise_size).to(device)\n",
        "        fake_images = decoder(z)\n",
        "\n",
        "        # Compare result of discriminator with fake images & real labels\n",
        "        # If generator deceives discriminator, g_loss will decrease\n",
        "        g_loss = criterion(discriminator(fake_images), real_label)\n",
        "\n",
        "        # Train generator with backpropagation\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # +---------------------+\n",
        "        # | train Discriminator |\n",
        "        # +---------------------+\n",
        "\n",
        "        # Initialize grad\n",
        "        d_optimizer.zero_grad()\n",
        "        g_optimizer.zero_grad()\n",
        "\n",
        "        # make fake images with generator & noise vector 'z'\n",
        "        noisy_z = noisy_z.detach().to(device)\n",
        "        # noisy_z = torch.randn(batch_size, noise_size).to(device)\n",
        "        fake_images = decoder(noisy_z)\n",
        "\n",
        "        # Calculate fake & real loss with generated images above & real images\n",
        "        fake_loss = criterion(discriminator(fake_images), fake_label)\n",
        "        real_loss = criterion(discriminator(real_images), real_label)\n",
        "        d_loss = (fake_loss + real_loss) / 2\n",
        "\n",
        "        # Train discriminator with backpropagation\n",
        "        # In this part, we don't train generator\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        d_performance = discriminator(real_images).mean()\n",
        "        g_performance = discriminator(fake_images).mean()\n",
        "\n",
        "        if (i + 1) % 150 == 0:\n",
        "            print(\"Epoch [ {}/{} ]  Step [ {}/{} ]  d_loss : {:.5f}  g_loss : {:.5f}\"\n",
        "                  .format(epoch, num_epoch, i+1, len(train_loader), d_loss.item(), g_loss.item()))\n",
        "\n",
        "    # print discriminator & generator's performance\n",
        "    print(\" Epock {}'s discriminator performance : {:.2f}  generator performance : {:.2f}\"\n",
        "          .format(epoch, d_performance, g_performance))\n",
        "\n",
        "    # images test\n",
        "    test_x = view_data.to(DEVICE)\n",
        "    zz = encoder(test_x)\n",
        "    decoded_data = decoder(zz)\n",
        "\n",
        "    # 원본과 디코딩 결과 비교해보기\n",
        "    f, a = plt.subplots(2, 5, figsize=(5, 2))\n",
        "    for i in range(5):\n",
        "        img = np.reshape(view_data.data.numpy()[i],(28, 28))\n",
        "        a[0][i].imshow(img, cmap='gray')\n",
        "        a[0][i].set_xticks(()); a[0][i].set_yticks(())\n",
        "\n",
        "    for i in range(5):\n",
        "        img = np.reshape(decoded_data.to(\"cpu\").data.numpy()[i], (28, 28))\n",
        "        a[1][i].imshow(img, cmap='gray')\n",
        "        a[1][i].set_xticks(()); a[1][i].set_yticks(())\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SgM3fG1_NPIn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}