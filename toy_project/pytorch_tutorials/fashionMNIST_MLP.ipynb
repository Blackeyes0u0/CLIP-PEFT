{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c106detail19maybe_wrap_dim_slowIxEET_S2_S2_b\n",
      "  Referenced from: <870081F6-12FD-3CEA-BC5C-30F4764F2A98> /Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torchvision/image.so\n",
      "  Expected in:     <F2FE5CF8-5B5B-3FAD-ADF8-C77D90F49FC9> /Users/juniverse/opt/anaconda3/envs/veda/lib/python3.8/site-packages/torch/lib/libc10.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # 뉴럴넷으로 패션 아이템 구분하기\n",
    "# Fashion MNIST 데이터셋과 앞서 배운 인공신경망을 이용하여 패션아이템을 구분해봅니다.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "\n",
    "# ## 데이터셋 불러오기\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "trainset = datasets.FashionMNIST(\n",
    "    root      = './../VAE_GAN/data/', \n",
    "    train     = True,\n",
    "    download  = True,\n",
    "    transform = transform\n",
    ")\n",
    "testset = datasets.FashionMNIST(\n",
    "    root      = './../VAE_GAN/data/', \n",
    "    train     = False,\n",
    "    download  = True,\n",
    "    transform = transform\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = trainset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset     = testset,\n",
    "    batch_size  = BATCH_SIZE,\n",
    "    shuffle     = True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] Test Loss: 0.8532, Accuracy: 68.32%\n",
      "[2] Test Loss: 0.6709, Accuracy: 76.15%\n",
      "[3] Test Loss: 0.6070, Accuracy: 77.95%\n",
      "[4] Test Loss: 0.5720, Accuracy: 79.10%\n",
      "[5] Test Loss: 0.5160, Accuracy: 81.66%\n",
      "[6] Test Loss: 0.4972, Accuracy: 82.35%\n",
      "[7] Test Loss: 0.4745, Accuracy: 83.39%\n",
      "[8] Test Loss: 0.4767, Accuracy: 83.25%\n",
      "[9] Test Loss: 0.4702, Accuracy: 82.77%\n",
      "[10] Test Loss: 0.4468, Accuracy: 83.87%\n",
      "[11] Test Loss: 0.4853, Accuracy: 81.86%\n",
      "[12] Test Loss: 0.4459, Accuracy: 83.90%\n",
      "[13] Test Loss: 0.4507, Accuracy: 83.94%\n",
      "[14] Test Loss: 0.4252, Accuracy: 84.96%\n",
      "[15] Test Loss: 0.4416, Accuracy: 84.25%\n",
      "[16] Test Loss: 0.4220, Accuracy: 85.46%\n",
      "[17] Test Loss: 0.4104, Accuracy: 85.60%\n",
      "[18] Test Loss: 0.4324, Accuracy: 84.99%\n",
      "[19] Test Loss: 0.4036, Accuracy: 85.59%\n",
      "[20] Test Loss: 0.4064, Accuracy: 85.41%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ## 뉴럴넷으로 Fashion MNIST 학습하기\n",
    "# 입력 `x` 는 `[배치크기, 색, 높이, 넓이]`로 이루어져 있습니다.\n",
    "# `x.size()`를 해보면 `[64, 1, 28, 28]`이라고 표시되는 것을 보실 수 있습니다.\n",
    "# Fashion MNIST에서 이미지의 크기는 28 x 28, 색은 흑백으로 1 가지 입니다.\n",
    "# 그러므로 입력 x의 총 특성값 갯수는 28 x 28 x 1, 즉 784개 입니다.\n",
    "# 우리가 사용할 모델은 3개의 레이어를 가진 인공신경망 입니다. \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# ## 모델 준비하기\n",
    "# `to()` 함수는 모델의 파라미터들을 지정한 곳으로 보내는 역할을 합니다.\n",
    "# 일반적으로 CPU 1개만 사용할 경우 필요는 없지만,\n",
    "# GPU를 사용하고자 하는 경우 `to(\"cuda\")`로 지정하여 GPU로 보내야 합니다.\n",
    "# 지정하지 않을 경우 계속 CPU에 남아 있게 되며 빠른 훈련의 이점을 누리실 수 없습니다.\n",
    "# 최적화 알고리즘으로 파이토치에 내장되어 있는 `optim.SGD`를 사용하겠습니다.\n",
    "\n",
    "model        = Net().to(DEVICE)\n",
    "optimizer    = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# ## 학습하기\n",
    "\n",
    "def train(model, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # 학습 데이터를 DEVICE의 메모리로 보냄\n",
    "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "# ## 테스트하기\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
    "            output = model(data)\n",
    "\n",
    "            # 모든 오차 더하기\n",
    "            test_loss += F.cross_entropy(output, target,\n",
    "                                         reduction='sum').item()\n",
    "            \n",
    "            # 가장 큰 값을 가진 클래스가 모델의 예측입니다.\n",
    "            # 예측과 정답을 비교하여 일치할 경우 correct에 1을 더합니다.\n",
    "            pred = output.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "\n",
    "# ## 코드 돌려보기\n",
    "# 자, 이제 모든 준비가 끝났습니다. 코드를 돌려서 실제로 훈련이 되는지 확인해봅시다!\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    \n",
    "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
    "          epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "veda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
