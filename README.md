# <center> Vector Universe </center>
---

<center>

![GitHub ë¡œê³ ](README_image/0u0.png)

</center>

#### <center> JoongHyun Shin </center>

<br>

##### <right>#CLIP #LoRA #Embeddings #Youtube Multimodal </right>

---
# 1. Datasets

![Alt text](image-2.png)

#### youtube thumbnails data

$I^{(i)}$ : youtube thumbnail Image data $i$
$T^{(i)}$ : youtube Title data $i$

#### Example 

$I^{(i)}$ : ![Alt text](image-1.png)

$T^{(i)}$ : **Cutest Cats Compilation 2017 | Best Cute Cat Videos Ever**


---
# 2. Model & Loss Architecture

<!-- 
![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png) -->

<!-- ![Alt text](image-5.png) -->
![Alt text](image-7.png)

ìœ„ ëª¨ë¸ ì•„í‚¤í…ì³ë¥¼ ë³´ë©´ Latent space ìƒì—ì„œ ì´ë¯¸ì§€ ì„ë² ë”©ê³¼ í…ìŠ¤íŠ¸ ì„ë² ë”©ì˜ ê±°ë¦¬ë¥¼ ê°€ê¹ê²Œ í•˜ëŠ”ê²ƒì„ alignment, ë©€ê²Œí•˜ëŠ”ê²ƒì„ Uniformë¼ê³  ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.

- LoRA ì„¤ëª…
#### https://velog.io/@blackeyes0u0/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-LoRA-Low-Rank-Adaptation-of-Large-Language-Models

- model ì„¤ëª…
### https://velog.io/@blackeyes0u0/youtube-CLIP-LoRA-SimCSE-%EA%B2%B0%EA%B3%BC

---


# 3. Objective function

$$
h_i = f(x_i)
$$

$$
\ell_i=-\log \frac{e^{\operatorname{sim}\mathbf{h}_i^{z_i}, \mathbf{h}_i^{z_i^{\prime}} / \tau}}{\sum_{j=1}^N e^{\operatorname{sim}\mathbf{h}_i^{z_i}, \mathbf{h}_j^{z_j^{\prime}} / \tau}}
$$

$i$ ë²ˆì§¸ ë°ì´í„°ì™€ $N$ê°œì˜ batch_size pair ëŒ€í•´ì„œ ìœ„ì™€ ê°™ì´ í‘œí˜„ í•  ìˆ˜ìˆë‹¤. 

$h_i$ëŠ” ë°ì´í„°ì˜ ì„ë² ë”©ì— í•´ë‹¹í•˜ê³ , $z_i$ëŠ” ê° ë°ì´í„°ì— ê°€í•œ augmentationì— í•´ë‹¹í•œë‹¤. $\tau$ëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„° temperatureê°’ì´ë‹¤.


<!-- ![Alt text](image-3.png) -->

<!-- ![Alt text](image-6.png) -->

$$
\mathcal{L} = \sum_{i=1}^{N} log \exp^ {-\frac{1}{\tau}  sim(h_i,h_i^+)} (Alignment)
$$

$$
+\sum_{i=1}^{N} log \sum_{j=1 }^{N} \exp^{\frac{1}{\tau} sim(h_i,h_j)} (Uniform)
$$


ì—¬ê¸°ì„œ ë‚˜ì˜¤ëŠ” simì€ similarityì˜ ì•½ìì´ê³ , cosine similarityë¥¼ ì‚¬ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.

### Notation

ië²ˆì§¸ image embedding : $I_i$ ëŠ” row vector

ië²ˆì§¸ text embedding : $T_i$

**(ë‹¨, $I_i,T_j,I_i^+,T_j^+$ëŠ” 1ë¡œ normalize)**

ì½”ë“œ ìƒì—ì„œëŠ” cosine similarityë¥¼ ì‚¬ìš©í•´ì„œ normalizeí•˜ì˜€ìŠµë‹ˆë‹¤.

$$
I_i = \mathbb M(batchsize,d=512)[i]
$$

## Image Text Alignment & Uniform

$$
alignment = -\sum_i tr(II^{+T}+I T^T+ I^+ T^{+T}+TT^{+T})
$$


ë¨¼ì € ìœ„ Object functionì—ì„œ Uniformì‹ì´ ì•„ë˜ì™€ ê°™ì´ ë˜ê¸° ìœ„í•´ì„œëŠ” convex functionë¼ê³  ê°€ì •í•˜ê³ , jensen's inequalityë¥¼ ì‚¬ìš©í•œ ê²°ê³¼ì…ë‹ˆë‹¤.

$$
Uniform = \sum_i \sum_{j } I_i \cdot T_j^T + \cdots \\
= sum(II^{+T}+I T^T+ I^+ T^{+T}+TT^{+T})
$$



ìœ„ ì‹ì„ ë¶„ì‚°ê³¼ í‰ê·  ê´€ì ì—ì„œ ë‹¤ì‹œ ë°”ë¼ë³´ì•˜ìŠµë‹ˆë‹¤.
$I_i$ê°€ í•œê°œì˜ ì„ë² ë”© ê°’ì´ë¼ê³  í•˜ê³ , ì´ ê°’ë“¤ì€ ê° í‰ê· ê³¼ ë¶„ì‚°ì„ ê°–ëŠ”ë‹¤ê³  í•˜ë©´, ì ì ˆí•œ ì„ë² ë”©ì€ ì–´ëŠ í•œ ì°¨ì›ìœ¼ë¡œ ì ë¦¬ì§€ ì•Šê³  ì ì ˆí•˜ê²Œ ë¶„ì‚°ë˜ì–´ì„œ í‘œí˜„ë˜ëŠ”ê²ƒ ì…ë‹ˆë‹¤.

ì´ê²ƒì— ëŒ€í•œ ì†”ë£¨ì…˜ìœ¼ë¡œëŠ” PCA whiteningê³¼ batch normalizationì´ê°€ ìƒê°ì´ ë‚©ë‹ˆë‹¤. ë¬´ì—‡ì„ ì‚¬ìš©í•´ì•¼í• ì§€ëŠ” ì•Œê¸° ìœ„í•´ ìˆ˜ì‹ì„ ì „ê°œí•´ ë³´ì•˜ìŠµë‹ˆë‹¤.

$$
I_i = \mu +\sigma_i \\
\mu = \frac{1}{N}\sum_{i \in \chi}^N I_i\\
\therefore \frac{1}{N}\sum_{i \in \chi}^N \sigma_i = 0
$$
$I$ë§Œ ìƒê°í•´ë³´ë©´,
$$
\frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j \in \chi}^N I_i \cdot I_j^T 
$$

$$
= \frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j \in \chi }^N (\mu +\sigma_i ) \cdot (\mu +\sigma_j )^T
$$

$$
=\mu \mu^T + \frac{1}{N^2}\sum_{i \in \chi }^N \sum_{j \in \chi}^N \sigma_i \cdot \sigma_j^T \\
=  I \cdot I^T = A
$$

ê°€ ë˜ì–´ì„œ ëœ»ì„ í•´ì„í•´ë³´ë©´ ì„ë² ë”©ì˜ í‰ê· ê°’ì„ ë‚®ì¶”ê³ , ë¶„ì‚°ì˜ ê³±ì„ ë‚®ì¶”ëŠ” ì‹ì´ë‹¤. ë˜í•œ, ìœ„ ì‹ì€ symmetric matrixì´ê¸° ë•Œë¬¸ì— í•­ìƒ diagonalizableí•˜ê³ , ê·¸ eigen vectorëŠ” orthogonal í•©ë‹ˆë‹¤.

ê·¸ëŸ¬í•œ ê²½ìš°ë¥¼ eigen decompositoiní•´ì„œ ìƒê°í•´ë³´ì.
$A$ë¼ê³  ë†“ì€ í–‰ë ¬ì„ $A P_i = \lambda_i P_i$ë¼ê³  ìƒê°í•´ë³´ì. ì´ë•Œ $P_i$ëŠ” $\lambda_i$ì— ëŒ€í•œ eigen vectorì…ë‹ˆë‹¤.

$$ 
A = P DP^T
$$

ì´ë•Œ, $PP^T = E$ ì¦‰, orthogonalí•˜ë¯€ë¡œ, 

$$
A = \sum_i \lambda_i P_i \cdot P_i^T
$$

$\lambda_i$ì˜ ì–´ëŠ í•œê°’ì´ í¬ë‹¤ëŠ” ê²ƒì€ ë°ì´í„°ê°€ ê³¨ê³ ë£¨ í¼ì ¸ìˆê¸°ë³´ë‹¨, í•œ ë°©í–¥ìœ¼ë¡œ ì¹˜ìš°ì³ì ¸ìˆëŠ”ê²ƒì´ë‹¤. ë”°ë¼ì„œ ìœ„ eigen valueê°’ì„ ê³¨ê³ ë£¨ ë§Œë“œëŠê²ƒì´ ì—¬ê¸°ì„œ ë‚˜ì˜¨ Uniformì˜ ëª©ì ì…ë‹ˆë‹¤. 

### Flatten Embedding

ìœ„ ëª©ì ì„ ì´ë£¨ê¸° ìœ„í•´ì„œ ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œìš”??

ë§Œì•½ì— $I_i$ê°€ normalize ë˜ì–´ìˆë‹¤ê³  í•œë‹¤ë©´, $tr(A)$ì˜ ê°’ì€ sum of eigen valueì´ê³ , constantí• ê²ƒì´ë‹¤. ì™œëƒí•˜ë©´ diagonal elementê°€ ëª¨ë‘ 1ì´ê¸° ë•Œë¬¸ì—.
ê·¸ë ‡ë‹¤ë©´ largest eigen valueì˜ ê°’ì„ ì¤„ì´ê³ , smallestí•œ eigen valueì˜ ê°’ì„ í‚¤ìš°ë©´ ë©ë‹ˆë‹¤. 

ë§Œì•½ì— , Aì˜ ê°’ë“¤ì´ ëª¨ë‘ ì–‘ìˆ˜ì´ê³ , $sum(P_i \cdot P_i^T)$ê°€ ì–‘ìˆ˜ë¼ë©´ sum($A$)ë¥¼ largest eigen valueì˜ upper boundì™€ ë¹„ë¡€í•œë‹¤ê³  ë†“ì„ ìˆ˜ ìˆë‹¤. ê·¸ë˜ì„œ ìœ„ sumì„ ì¤„ì´ëŠ”ê²ƒì´, flatten embeddingì„ í•˜ë©´ì„œ negative pairë¼ë¦¬ì˜ ì„ë² ë”©ì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

SimCSE ë…¼ë¬¸ì˜ ì•„ì´ë””ì–´ë¥¼ ì¸ìš©í•˜ì˜€ìŠµë‹ˆë‹¤.
https://arxiv.org/abs/2104.08821

---

## Flatten different Embeddings

í•˜ì§€ë§Œ ë‚˜ëŠ” ê·¸ë ‡ê²Œ ì¡°ê±´ì„ ì¤„ ìˆ˜ ì—†ê¸°ì—, ë‹¤ë¥¸ ë°©ì‹ì„ ìƒê°í•´ì•¼ í–ˆìŠµë‹ˆë‹¤. ì´ìœ , ë‹¤ë¥¸ ì„ë² ë”©ë¼ë¦¬ì˜ í‘œí˜„ì´ê¸° ë•Œë¬¸ì—..

ê·¸ë˜ì„œ ìœ„ì²˜ëŸ¼ negative pair lossì™€ Uniformë¥¼ í•˜ë‚˜ì˜ ì‹ìœ¼ë¡œ ë³´ì§€ì•Šê³ , ë”°ë¡œ ë³¼ ìƒê°ì…ë‹ˆë‹¤.
ì´ì œ Iì™€ Tì— ëŒ€í•´ì„œ ìƒê°í•´ ë´…ì‹œë‹¤.

### negative pair loss

$$
\frac{1}{N^2}\sum_{i \in \chi }^N \sum_{j  \in \Chi}^N I_i \cdot T_j^T 
$$

$$
= \frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j  \in \Chi}^N (\mu^{(Image)} +\sigma_i^{(Image)} ) \cdot (\mu^{(Text)} +\sigma_j^{(Text)} )^T
$$

$$
=\mu^{(Image)} \mu^{(Text)T} + \frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j  \in \Chi}^N \sigma_i \cdot \sigma_j^T
$$

ì§ê´€ì ì¸ ì˜ë¯¸ë¥¼ ë³´ìë©´, ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ì˜ í‰ê·  ê°’ì„ ì¤„ì´ê³ , ê° ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ì„ë² ë”©ì˜ ì„œë¡œ ë‹¤ë¥¸ ë¶„ì‚° ì„ë² ë”©ì„ ì¤„ì´ëŠ” ê²ƒì…ë‹ˆë‹¤. ë¨¼ì € ì´ê±¸ë¡œ, negative pairë¼ë¦¬ì˜ dot productê°’ì„ ì¤„ì—¬, cosine similarityë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

## Objective function code
```python
from abc import ABC
from abc import abstractmethod
# static method
class Loss(ABC):
    # @abstractmethod
    # def __init__(self) -> None:
        # super().__init__()
        
    @abstractmethod
    def Alignment(self) -> None:
        """Define layers in ther model."""
        raise NotImplementedError
    
    @abstractmethod
    def Uniform(self) -> None:
        """Define layers in ther model."""
        raise NotImplementedError
    def Total_loss(self) -> None:
        """Define layers in ther model."""
        raise NotImplementedError
import torch
import torch.nn.functional as F

class SimLoss(Loss): # what i want to similar
    def __init__(self,hi1:torch.tensor
                ,ht1:torch.tensor
                ,hi2:torch.tensor
                ,ht2:torch.tensor
                ):
        self.hi1 = hi1
        self.ht1 = ht1
        self.hi2 = hi2
        self.ht2 = ht2
        self.tau = 1/0.05
        self.batch_size = batch_size
        
    def Alignment(self):
        Alii  = -(self.tau*F.cosine_similarity(self.hi1,self.hi2))
        Alit1 = -(self.tau*F.cosine_similarity(self.hi1,self.ht1))
        Alit2 = -(self.tau*F.cosine_similarity(self.hi2,self.ht2))
        Altt = -(self.tau*F.cosine_similarity(self.ht1,self.ht2))
        return (ALii+ALtt+Alit1+Alit2)#/self.batch_size
    
    def Uniform(self):
        Uniform = torch.empty(batch_size)
        for i in range(batch_size):
            Ii1 = self.hi1[i]
            Ii2 = self.hi2[i]
            Ti1 = self.ht1[i]
            Ti2 = self.ht2[i] 
            Uniformj = 0
            for j in range(batch_size):
                if i!=j:
                    Ij1 = self.hi1[j]
                    Ij2 = self.hi2[j]
                    Tj1 = self.ht1[j]
                    Tj2 = self.ht2[j] 
                    Uniformj+=F.cosine_similarity(Ii1,Ij1,dim=0)
                    Uniformj+=F.cosine_similarity(Ti2,Tj2,dim=0)
                    Uniformj+=F.cosine_similarity(Ii1,Tj1,dim=0)
                    Uniformj+=F.cosine_similarity(Ii2,Tj2,dim=0)
                    # tau ê°’ì„ ë„£ìœ¼ë©´ ë„ˆë¬´ ì»¤ì ¸ì„œ ì•ˆë¨ .. batch sizeì— ë”°ë¼ì„œ ì¡°ì ˆí•´ì•¼í• ë“¯..        
            Uniform[i] = Uniformj/self.batch_size#*tau
        return Uniform
    
    def Total_loss(self,device):
        alignment  = self.Alignment().to(device)
        Uniform = self.Uniform().to(device)
        return torch.sum(alignment+Uniform)/batch_size
```

# Train
```python
def train(lora_model,device,train_dataloader,train_dataloader2):
    for step,((img,texts),(img2,texts2))in enumerate(zip(train_dataloader,train_dataloader2)):
        optimizer.zero_grad()

        dict1 = {}
        dict1['input_ids'] = texts.to(device)
        dict1['pixel_values'] = img.to(device)

        dict2 = {}
        dict2['input_ids'] = texts2.to(device)
        dict2['pixel_values'] = img2.to(device)
        
        y1 = lora_model(**dict1)
        y2 = lora_model(**dict2)

        image_embeddings = y1.image_embeds
        text_embeddings = y1.text_embeds

        image_embeddings2 = y2.image_embeds
        text_embeddings2 = y2.text_embeds

        # loss function
        loss = SimLoss(hi1=image_embeddings,
                             ht1=text_embeddings,
                             hi2=image_embeddings2,
                             ht2=text_embeddings2)
        alignment = loss.Alignment().to(device)
        Uniform = loss.Uniform().to(device)
        
        total_loss = torch.sum(alignment+Uniform)/batch_size
        total_loss.backward()
        optimizer.step()

        if step%10==0:
            wandb.log({"Learning rate":lr,"total_loss": total_loss.item(), "alignment_loss": alignment_loss,"Uniform_loss":Uniform_loss})
            print(step,"'s batch  ",'  &loss :',round(total_loss.item(),5),'alignment : ',round(alignment.mean().item(),4),' Uniform :',round(Uniform.mean().item(),4))
            print('lr :',lr)
```

## Experiments 

```python
 0%|          | 0/15 [00:00<?, ?it/s]
##################
Epoch :  0
##################
0 's batch     &loss : 0.1842 alignment1,2 :  -0.088 -0.087  Uniform : 0.359
lr : 1.2352941176470589e-05
10 's batch     &loss : 0.1743 alignment1,2 :  -0.088 -0.087  Uniform : 0.349
lr : 3.5882352941176474e-05
20 's batch     &loss : 0.154 alignment1,2 :  -0.082 -0.082  Uniform : 0.319
lr : 4.944045828160822e-05
####################
validation!!
  7%|â–‹         | 1/15 [02:48<39:23, 168.80s/it]
valid_loss : 0.11913358100822993 valid_alignment -0.07925071428571429 valid_Uniform 0.2775714285714285


									!! ì¤‘ê°„ ìƒëµ !!


 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 14/15 [38:31<02:44, 164.59s/it]
valid_loss : -1.340464472770691 valid_alignment 0.31172999999999995 valid_Uniform -1.964
####################
##################
Epoch :  14
##################
0 's batch     &loss : -1.3409 alignment1,2 :  0.312 0.312  Uniform : -1.965
lr : 2.0051537954535784e-05
10 's batch     &loss : -1.3403 alignment1,2 :  0.311 0.312  Uniform : -1.964
lr : 1.4550932728463223e-05
```

<!-- 
<br>

#### Preprocess & Tokenize
$I_{}^{\prime(i)} = Preprocesser(I^{(i)})$ : CLIP  Preprocess (parameter freeze $\Phi_0$)

$T_{}^{\prime(i)} = Tokenizer(T^{(i)})$ : CLIP Tokenizer (parameter freeze $\Phi_0$)

$Y_{}^{\prime(i)} = Tokenizer(Y^{(i)})$ : CLIP Tokenizer (parameter freeze $\Phi_0$)


<br>

#### Embeddings 
$E_I(I_{}^{\prime(i)};\theta_I)$ : CLIP Image Encoder + LoRA  (learnable params : $\theta_I$)
$E_T(T_{}^{\prime(i)};\theta_T)$ : CLIP Text Encoder + LoRA (learnable params : $\theta_T$)

$E_T(Y_{}^{\prime(i)};\theta_T)$ : CLIP Text Encoder + LoRA (learnable params : $\theta_T$)

#### Concat Image embeddings and Text embeddings

$X^{(i)} = f^{}(E_I(I_{}^{\prime(i)}),E_T(T_{}^{\prime(i)});\Psi)$

$f(\cdot)$ : Image + Text concat models (learnable params : $\Psi$)

<br>

#### Kernel method 

$\psi(X^{(i)})^T \cdot \phi(E_T(Y_{}^{\prime(i)}))$

<br>
miminize KL-divergence
-->







---

### Installation 

#### transformers & peft & loralib

ğŸ¤— Transformers is tested on Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, and Flax. Follow the installation instructions below for the deep learning library you are using:

PyTorch installation : [pytorch](https://pytorch.org/get-started/locally/)

TensorFlow 2.0 installation instructions : [tensorflow](https://www.tensorflow.org/install/pip)
Flax installation instructions.[Flax](https://flax.readthedocs.io/en/latest/)


```
python -m venv .env
```
Activate the virtual environment. On Linux and MacOs:

```
source .env/bin/activate
```
Activate Virtual environment on Windows
```
.env/Scripts/activate
```
Now youâ€™re ready to install ğŸ¤— Transformers with the following command:
```
pip install transformers
```
For CPU-support only, you can conveniently install ğŸ¤— Transformers and a deep learning library in one line. For example, install ğŸ¤— Transformers and PyTorch with:
```
/VectorUniverse Project X
â”œâ”€â”€ README.md
â”œâ”€â”€ Data
|  â”œâ”€â”€ VQA
|  â””â”€â”€ Youtube_thumbnails
|       â”œâ”€â”€ images
|       â””â”€â”€ metadata.csv
|
â”œâ”€â”€ node_modules
|  â”œâ”€â”€ bluebird
|  â”œâ”€â”€ chalk
|  â”œâ”€â”€ cli-spinner
|  â”œâ”€â”€ meow
|  â””â”€â”€ object-assign
â”œâ”€â”€ package.json
â””â”€â”€ tree.js
```
