# <center> Vector Universe </center>
---

<center>

![GitHub Î°úÍ≥†](README_image/0u0.png)

</center>

#### <center> JoongHyun Shin </center>

<br>

##### <right>#CLIP #LoRA #Embeddings #Youtube Multimodal </right>

---
# 1. Datasets

![Alt text](image-2.png)

#### youtube thumbnails data

$I^{(i)}$ : youtube thumbnail Image data $i$
$T^{(i)}$ : youtube Title data $i$
$Y^{(i)}$ : youtube Label data $i$

#### Example 

$I^{(i)}$ : ![Alt text](image-1.png)

$T^{(i)}$ : **Cutest Cats Compilation 2017 | Best Cute Cat Videos Ever**

$Y^{(i)}$ : **Animal, Cat, Blog, daily**

---
# 2. Model & Loss Architecture

>####Model Architecture
### LoRA

![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/peft/lora_diagram.png)

![Alt text](image-5.png)

reference
https://velog.io/@blackeyes0u0/%EB%85%BC%EB%AC%B8%EB%A6%AC%EB%B7%B0-LoRA-Low-Rank-Adaptation-of-Large-Language-Models

---

>####Loss Architecture

# 3. Objective function

<!-- N = batch_size -->
<!-- sim  = cosine, mutual information, euclidean distance -->

$$
\mathcal{L} = \sum_{i=1}^{N} log \exp^ {-\frac{1}{\tau}  sim(h_i,h_i^+)} (Alignment)
$$

$$
+\sum_{i=1}^{N} log \sum_{j \neq i}^{N} \exp^{\frac{1}{\tau} sim(h_i,h_j)} (Anisotropy)
$$


reference :
https://github.com/Blackeyes0u0/Blackeyes0u0-paper-review/blob/master/papers/Language/simCSE/simcse.md



<!-- ![Alt text](image-3.png) -->
![Alt text](image-7.png)
<!-- ![Alt text](image-6.png) -->


# Objective function


$$
\mathcal{L} = \sum_{i=1}^{N} log \exp^ {-\frac{1}{\tau}  sim(h_i,h_i^+)} (Alignment)
$$
$$
+ \sum_{i=1}^{N} log \sum_{j \neq i}^{N} \exp^{\frac{1}{\tau} sim(h_i,h_j)} (Anisotropy)
$$
$$
h_i = f(x_i), N = batchsize
$$
Ïó¨Í∏∞ÏÑú ÎÇòÏò§Îäî simÏùÄ similarityÏùò ÏïΩÏûêÏù¥Í≥†, cosine similarityÎ•º ÏÇ¨Ïö©ÌïòÏòÄÎã§.

ÎÇ¥Í∞Ä base modelÎ°ú ÏÇ¨Ïö©Ìïú CLIPÏùÄ imageÏôÄ textÍ∞ÑÏùò alignmentÏôÄ anisotropyÍ∞Ä Ïûò ÎêòÏñ¥ÏûàÎã§Í≥† Í∞ÄÏ†ïÏùÑ ÌïòÏòÄÏßÄÎßå, Ï†ÑÏ≤¥ ÏãùÏúºÎ°ú Ï†ÑÎ∂Ä ÌôïÏû•ÌïòÎäîÍ≤ÉÏù¥ ÎßûÎäîÍ≤ÉÍ∞ôÏïÑÏÑú ÏßÑÌñâÌï¥Î≥¥Ïûê.

### Notation
iÎ≤àÏß∏ image embedding : $I_i$ Îäî row vectorÎùºÍ≥† Í∞ÄÏ†ïÌïòÏûê.
iÎ≤àÏß∏ text embedding : $T_i$
**(Îã®, $I_i,T_j,I_i^+,T_j^+$Îäî 1Î°ú normalizeÎêòÏñ¥ ÏûàÎã§.) **
ÏΩîÎìúÎ•º Ïß§ÎïåÎäî, cosine similarityÎ•º ÏÇ¨Ïö©Ìï¥ÏÑú normalizeÏãúÏº∞Îã§.

$$
I_i = \mathbb M(batchsize,d=512)[i] \\
I, I^+,T, T^+ 
$$
$$
alignment = -[sim(I,I^+)+sim(I,T)+sim(I^+,T^+)+sim(T,T^+)] 
$$


Î®ºÏ†Ä ÏúÑ Object functionÏóêÏÑú anisotropyÏãùÏù¥ ÏïÑÎûòÏôÄ Í∞ôÏù¥ ÎêòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî convex functionÎùºÍ≥† Í∞ÄÏ†ïÌïòÍ≥†, jensen's inequalityÎ•º ÏÇ¨Ïö©Ìïú Í≤∞Í≥ºÏù¥Îã§.
$$
anisotropy = \sum_i \sum_{j \neq i} I_i \cdot T_j^T + \cdots \\
= sum(I T^T) + sum(I^+ T^{+T})+sum(II^{+T}) + sum(TT^{+T}) +C
$$
(Îã®, $I_i,T_j,I_i^+,T_j^+$Îäî 1Î°ú normalizeÎêòÏñ¥ ÏûàÎã§.) Í∑∏ÎûòÏïºÎßå CÎ°ú ÏπòÌôòÌï¥ÏÑú ÏÉÅÏàòÎ°ú Ï∑®Í∏âÌï† Ïàò ÏûàÎã§..

Îã§ÏùåÍ≥º ÌñâÎ†¨ÏùÄ (batch_size*batch_size)ÌÅ¨Í∏∞Ïùò ÌñâÎ†¨Ïù¥Îã§.

ÏúÑ ÏãùÏùÑ Î∂ÑÏÇ∞Í≥º ÌèâÍ∑† Í¥ÄÏ†êÏóêÏÑú Îã§Ïãú Î∞îÎùºÎ≥¥Ïûê.
$I_i$Í∞Ä ÌïúÍ∞úÏùò ÏûÑÎ≤†Îî© Í∞íÏù¥ÎùºÍ≥† ÌïòÍ≥†, Ïù¥ Í∞íÎì§ÏùÄ Í∞Å ÌèâÍ∑†Í≥º Î∂ÑÏÇ∞ÏùÑ Í∞ñÎäîÎã§Í≥† Ìï¥Î≥¥Ïûê. Ïù¥Îü¥Îïå, Ï†ÅÏ†àÌïú ÏûÑÎ≤†Îî©ÏùÄ Ïñ¥Îäê Ìïú Ï∞®ÏõêÏúºÎ°ú Ïè†Î¶¨ÏßÄ ÏïäÍ≥† Ï†ÅÏ†àÌïòÍ≤å Î∂ÑÏÇ∞ÎêòÏñ¥ÏÑú ÌëúÌòÑÎêòÎäîÍ≤ÉÏù¥Îã§.
Ïù¥Í≤ÉÏóê ÎåÄÌïú ÏûêÎ£åÎäî PCA whiteningÍ≥º batch normalizationÏù¥ ÏÉùÍ∞ÅÎÇúÎã§. Î¨¥ÏóáÏùÑ ÏÇ¨Ïö©Ìï¥ÏïºÌï†ÏßÄÎäî Î®ºÏ†Ä ÏàòÏãùÏùÑ Ï†ÑÍ∞úÌï¥Î≥¥Ïûê.

$$
I_i = \mu +\sigma_i \\
\mu = \frac{1}{N}\sum_{i \in \chi}^N I_i\\
\therefore \frac{1}{N}\sum_{i \in \chi}^N \sigma_i = 0
$$
$I$Îßå ÏÉùÍ∞ÅÌï¥Î≥¥Î©¥,
$$
\frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j \in \chi}^N I_i \cdot I_j^T 
$$

$$
= \frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j \in \chi }^N (\mu +\sigma_i ) \cdot (\mu +\sigma_j )^T
$$

$$
=\mu \mu^T + \frac{1}{N^2}\sum_{i \in \chi }^N \sum_{j \in \chi}^N \sigma_i \cdot \sigma_j^T \\
=  I \cdot I^T = A
$$
Í∞Ä ÎêòÏñ¥ÏÑú ÎúªÏùÑ Ìï¥ÏÑùÌï¥Î≥¥Î©¥ ÏûÑÎ≤†Îî©Ïùò ÌèâÍ∑†Í∞íÏùÑ ÎÇÆÏ∂îÍ≥†, Î∂ÑÏÇ∞Ïùò Í≥±ÏùÑ ÎÇÆÏ∂îÎäî ÏãùÏù¥Îã§. ÎòêÌïú, ÏúÑ ÏãùÏùÄ symmetric matrixÏù¥Í∏∞ ÎïåÎ¨∏Ïóê Ìï≠ÏÉÅ diagonalizableÌïòÍ≥†, Í∑∏ eigen vectorÎäî orthogonal ÌïòÎã§.

Í∑∏Îü¨Ìïú Í≤ΩÏö∞Î•º eigen decompositoinÌï¥ÏÑú ÏÉùÍ∞ÅÌï¥Î≥¥Ïûê.
$A$ÎùºÍ≥† ÎÜìÏùÄ ÌñâÎ†¨ÏùÑ $A P_i = \lambda_i P_i$ÎùºÍ≥† ÏÉùÍ∞ÅÌï¥Î≥¥Ïûê. Ïù¥Îïå $P_i$Îäî $\lambda_i$Ïóê ÎåÄÌïú eigen vectorÏù¥Îã§.
$$ 
A = P DP^T
$$
Ïù¥Îïå, $PP^T = E$ Ï¶â, orthogonalÌïòÎØÄÎ°ú, 
$$
A = \sum_i \lambda_i P_i \cdot P_i^T
$$
$\lambda_i$Ïùò Ïñ¥Îäê ÌïúÍ∞íÏù¥ ÌÅ¨Îã§Îäî Í≤ÉÏùÄ Îç∞Ïù¥ÌÑ∞Í∞Ä Í≥®Í≥†Î£® ÌçºÏ†∏ÏûàÍ∏∞Î≥¥Îã®, Ìïú Î∞©Ìñ•ÏúºÎ°ú ÏπòÏö∞Ï≥êÏ†∏ÏûàÎäîÍ≤ÉÏù¥Îã§. Îî∞ÎùºÏÑú ÏúÑ eigen valueÍ∞íÏùÑ Í≥®Í≥†Î£® ÎßåÎìúÎäêÍ≤ÉÏù¥ anisotropyÏùò Î™©Ï†ÅÏù¥Îã§. 

### Flatten Embedding
ÏúÑ Î™©Ï†ÅÏùÑ Ïù¥Î£®Í∏∞ ÏúÑÌï¥ÏÑú Ïñ¥ÎñªÍ≤å Ìï¥ÏïºÌï†Íπå??

ÎßåÏïΩÏóê $I_i$Í∞Ä normalize ÎêòÏñ¥ÏûàÎã§Í≥† ÌïúÎã§Î©¥, $tr(A)$Ïùò Í∞íÏùÄ sum of eigen valueÏù¥Í≥†, constantÌï†Í≤ÉÏù¥Îã§. ÏôúÎÉêÌïòÎ©¥ diagonal elementÍ∞Ä Î™®Îëê 1Ïù¥Í∏∞ ÎïåÎ¨∏Ïóê.
Í∑∏Î†áÎã§Î©¥ largest eigen valueÏùò Í∞íÏùÑ Ï§ÑÏù¥Í≥†, smallestÌïú eigen valueÏùò Í∞íÏùÑ ÌÇ§Ïö∞Î©¥ ÎêúÎã§. 

ÎßåÏïΩÏóê , AÏùò Í∞íÎì§Ïù¥ Î™®Îëê ÏñëÏàòÏù¥Í≥†, $sum(P_i \cdot P_i^T)$Í∞Ä ÏñëÏàòÎùºÎ©¥ sum($A$)Î•º largest eigen valueÏùò upper boundÏôÄ ÎπÑÎ°ÄÌïúÎã§Í≥† ÎÜìÏùÑ Ïàò ÏûàÎã§. Í∑∏ÎûòÏÑú ÏúÑ sumÏùÑ Ï§ÑÏù¥ÎäîÍ≤ÉÏù¥, flatten embeddingÏùÑ ÌïòÎ©¥ÏÑú negative pairÎÅºÎ¶¨Ïùò ÏûÑÎ≤†Îî©ÏùÑ Ìï† Ïàò ÏûàÎã§Í≥† Î≥∏Îã§. 

SimCSE ÎÖºÎ¨∏Ïùò ÏïÑÏù¥ÎîîÏñ¥Î•º Ïù∏Ïö©ÌïòÏòÄÎã§.
https://arxiv.org/abs/2104.08821

---
## Flatten different Embeddings

ÌïòÏßÄÎßå ÎÇòÎäî Í∑∏Î†áÍ≤å Ï°∞Í±¥ÏùÑ Ï§Ñ Ïàò ÏóÜÍ∏∞Ïóê, Îã§Î•∏ Î∞©ÏãùÏùÑ ÏÉùÍ∞ÅÌï¥ÏïºÌïúÎã§. Ïù¥Ïú†, Îã§Î•∏ ÏûÑÎ≤†Îî©ÎÅºÎ¶¨Ïùò ÌëúÌòÑÏù¥Í∏∞ ÎïåÎ¨∏Ïóê..
Í∑∏ÎûòÏÑú ÏúÑÏ≤òÎüº ÌïòÎÇòÏùò ÏãùÏúºÎ°ú Î≥¥ÏßÄÏïäÍ≥†, Îî∞Î°ú Î≥º ÏûëÏ†ïÏù¥Îã§.
Ïù¥Ï†ú Î≥∏Í≤©Ï†ÅÏúºÎ°ú, IÏôÄ TÏóê ÎåÄÌï¥ÏÑú ÏÉùÍ∞ÅÌï¥Î≥¥Ïûê.
### negative pair loss

$$
\frac{1}{N^2}\sum_{i \in \chi }^N \sum_{j \neq i \in \Chi}^N I_i \cdot T_j^T 
$$

$$
= \frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j \neq i \in \Chi}^N (\mu^{(Image)} +\sigma_i^{(Image)} ) \cdot (\mu^{(Text)} +\sigma_j^{(Text)} )^T
$$

$$
=\mu^{(Image)} \mu^{(Text)T} + \frac{1}{N^2}\sum_{i \in \chi}^N \sum_{j \neq i \in \Chi}^N \sigma_i \cdot \sigma_j^T
$$
ÏßÅÍ¥ÄÏ†ÅÏù∏ ÏùòÎØ∏Î•º Î≥¥ÏûêÎ©¥, Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏Ïùò ÌèâÍ∑† Í∞íÏùÑ Ï§ÑÏù¥Í≥†, Í∞Å Ïù¥ÎØ∏ÏßÄÏôÄ ÌÖçÏä§Ìä∏ ÏûÑÎ≤†Îî©Ïùò ÏÑúÎ°ú Îã§Î•∏ Î∂ÑÏÇ∞ ÏûÑÎ≤†Îî©ÏùÑ Ï§ÑÏù¥Îäî Í≤ÉÏù¥Îã§. Î®ºÏ†Ä Ïù¥Í±∏Î°ú, negative pairÎÅºÎ¶¨Ïùò dot productÍ∞íÏùÑ Ï§ÑÏó¨, cosine similarityÎ•º Ï§ÑÏùº Ïàò ÏûàÎã§. 

## Objective function code
```python
from abc import ABC
from abc import abstractmethod
# static method
class Loss(ABC):
    # @abstractmethod
    # def __init__(self) -> None:
        # super().__init__()
        
    @abstractmethod
    def Alignment(self) -> None:
        """Define layers in ther model."""
        raise NotImplementedError
    
    @abstractmethod
    def Anisotropy(self) -> None:
        """Define layers in ther model."""
        raise NotImplementedError
    def Total_loss(self) -> None:
        """Define layers in ther model."""
        raise NotImplementedError
import torch
import torch.nn.functional as F

class SimLoss(Loss): # what i want to similar
    def __init__(self,hi1:torch.tensor
                ,ht1:torch.tensor
                ,hi2:torch.tensor
                ,ht2:torch.tensor
                ):
        self.hi1 = hi1
        self.ht1 = ht1
        self.hi2 = hi2
        self.ht2 = ht2
        self.tau = 1/0.05
        self.batch_size = batch_size
        
    def Alignment(self):
        Alii  = -(self.tau*F.cosine_similarity(self.hi1,self.hi2))
        Alit1 = -(self.tau*F.cosine_similarity(self.hi1,self.ht1))
        Alit2 = -(self.tau*F.cosine_similarity(self.hi2,self.ht2))
        Altt = -(self.tau*F.cosine_similarity(self.ht1,self.ht2))
        return (ALii+ALtt+Alit1+Alit2)#/self.batch_size
    
    def Anisotropy(self):
        anisotropy = torch.empty(batch_size)
        for i in range(batch_size):
            Ii1 = self.hi1[i]
            Ii2 = self.hi2[i]
            Ti1 = self.ht1[i]
            Ti2 = self.ht2[i] 
            anisotropyj = 0
            for j in range(batch_size):
                if i!=j:
                    Ij1 = self.hi1[j]
                    Ij2 = self.hi2[j]
                    Tj1 = self.ht1[j]
                    Tj2 = self.ht2[j] 
                    anisotropyj+=F.cosine_similarity(Ii1,Ij1,dim=0)
                    anisotropyj+=F.cosine_similarity(Ti2,Tj2,dim=0)
                    anisotropyj+=F.cosine_similarity(Ii1,Tj1,dim=0)
                    anisotropyj+=F.cosine_similarity(Ii2,Tj2,dim=0)
                    # tau Í∞íÏùÑ ÎÑ£ÏúºÎ©¥ ÎÑàÎ¨¥ Ïª§Ï†∏ÏÑú ÏïàÎê® .. batch sizeÏóê Îî∞ÎùºÏÑú Ï°∞Ï†àÌï¥ÏïºÌï†ÎìØ..        
            anisotropy[i] = anisotropyj/self.batch_size#*tau
        return anisotropy
    
    def Total_loss(self,device):
        alignment  = self.Alignment().to(device)
        anisotropy = self.Anisotropy().to(device)
        return torch.sum(alignment+anisotropy)/batch_size
```

# Train
```python
def train(lora_model,device,train_dataloader,train_dataloader2):
    for step,((img,texts),(img2,texts2))in enumerate(zip(train_dataloader,train_dataloader2)):
        optimizer.zero_grad()

        dict1 = {}
        dict1['input_ids'] = texts.to(device)
        dict1['pixel_values'] = img.to(device)

        dict2 = {}
        dict2['input_ids'] = texts2.to(device)
        dict2['pixel_values'] = img2.to(device)
        
        y1 = lora_model(**dict1)
        y2 = lora_model(**dict2)

        image_embeddings = y1.image_embeds
        text_embeddings = y1.text_embeds

        image_embeddings2 = y2.image_embeds
        text_embeddings2 = y2.text_embeds

        # loss function
        loss = SimLoss(hi1=image_embeddings,
                             ht1=text_embeddings,
                             hi2=image_embeddings2,
                             ht2=text_embeddings2)
        alignment = loss.Alignment().to(device)
        anisotropy = loss.Anisotropy().to(device)
        
        total_loss = torch.sum(alignment+anisotropy)/batch_size
        total_loss.backward()
        optimizer.step()

        if step%10==0:
            wandb.log({"Learning rate":lr,"total_loss": total_loss.item(), "alignment_loss": alignment_loss,"anisotropy_loss":anisotropy_loss})
            print(step,"'s batch  ",'  &loss :',round(total_loss.item(),5),'alignment : ',round(alignment.mean().item(),4),' anisotropy :',round(anisotropy.mean().item(),4))
            print('lr :',lr)
```

## Experiments 

```python
 0%|          | 0/15 [00:00<?, ?it/s]
##################
Epoch :  0
##################
0 's batch     &loss : 0.1842 alignment1,2 :  -0.088 -0.087  anisotropy : 0.359
lr : 1.2352941176470589e-05
10 's batch     &loss : 0.1743 alignment1,2 :  -0.088 -0.087  anisotropy : 0.349
lr : 3.5882352941176474e-05
20 's batch     &loss : 0.154 alignment1,2 :  -0.082 -0.082  anisotropy : 0.319
lr : 4.944045828160822e-05
####################
validation!!
  7%|‚ñã         | 1/15 [02:48<39:23, 168.80s/it]
valid_loss : 0.11913358100822993 valid_alignment -0.07925071428571429 valid_anisotropy 0.2775714285714285


									!! Ï§ëÍ∞Ñ ÏÉùÎûµ !!


 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 14/15 [38:31<02:44, 164.59s/it]
valid_loss : -1.340464472770691 valid_alignment 0.31172999999999995 valid_anisotropy -1.964
####################
##################
Epoch :  14
##################
0 's batch     &loss : -1.3409 alignment1,2 :  0.312 0.312  anisotropy : -1.965
lr : 2.0051537954535784e-05
10 's batch     &loss : -1.3403 alignment1,2 :  0.311 0.312  anisotropy : -1.964
lr : 1.4550932728463223e-05
```

<!-- 
<br>

#### Preprocess & Tokenize
$I_{}^{\prime(i)} = Preprocesser(I^{(i)})$ : CLIP  Preprocess (parameter freeze $\Phi_0$)

$T_{}^{\prime(i)} = Tokenizer(T^{(i)})$ : CLIP Tokenizer (parameter freeze $\Phi_0$)

$Y_{}^{\prime(i)} = Tokenizer(Y^{(i)})$ : CLIP Tokenizer (parameter freeze $\Phi_0$)


<br>

#### Embeddings 
$E_I(I_{}^{\prime(i)};\theta_I)$ : CLIP Image Encoder + LoRA  (learnable params : $\theta_I$)
$E_T(T_{}^{\prime(i)};\theta_T)$ : CLIP Text Encoder + LoRA (learnable params : $\theta_T$)

$E_T(Y_{}^{\prime(i)};\theta_T)$ : CLIP Text Encoder + LoRA (learnable params : $\theta_T$)

#### Concat Image embeddings and Text embeddings

$X^{(i)} = f^{}(E_I(I_{}^{\prime(i)}),E_T(T_{}^{\prime(i)});\Psi)$

$f(\cdot)$ : Image + Text concat models (learnable params : $\Psi$)

<br>

#### Kernel method 

$\psi(X^{(i)})^T \cdot \phi(E_T(Y_{}^{\prime(i)}))$

<br>
miminize KL-divergence
-->







---

### Installation 

#### transformers & peft & loralib

ü§ó Transformers is tested on Python 3.6+, PyTorch 1.1.0+, TensorFlow 2.0+, and Flax. Follow the installation instructions below for the deep learning library you are using:

PyTorch installation : [pytorch](https://pytorch.org/get-started/locally/)

TensorFlow 2.0 installation instructions : [tensorflow](https://www.tensorflow.org/install/pip)
Flax installation instructions.[Flax](https://flax.readthedocs.io/en/latest/)


```
python -m venv .env
```
Activate the virtual environment. On Linux and MacOs:

```
source .env/bin/activate
```
Activate Virtual environment on Windows
```
.env/Scripts/activate
```
Now you‚Äôre ready to install ü§ó Transformers with the following command:
```
pip install transformers
```
For CPU-support only, you can conveniently install ü§ó Transformers and a deep learning library in one line. For example, install ü§ó Transformers and PyTorch with:
```
/VectorUniverse Project X
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ Data
|  ‚îú‚îÄ‚îÄ VQA
|  ‚îî‚îÄ‚îÄ Youtube_thumbnails
|       ‚îú‚îÄ‚îÄ images
|       ‚îî‚îÄ‚îÄ metadata.csv
|
‚îú‚îÄ‚îÄ node_modules
|  ‚îú‚îÄ‚îÄ bluebird
|  ‚îú‚îÄ‚îÄ chalk
|  ‚îú‚îÄ‚îÄ cli-spinner
|  ‚îú‚îÄ‚îÄ meow
|  ‚îî‚îÄ‚îÄ object-assign
‚îú‚îÄ‚îÄ package.json
‚îî‚îÄ‚îÄ tree.js
```
